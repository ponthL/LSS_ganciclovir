---
title: "Valganciclovir"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(truncnorm)
library(mrgsolve)

library(mrgsolve)
library(mapbayr)

library(dplyr)

library(magrittr)
library(ggplot2)
library(PKNCA)
library(ggplot2)
library(ggcorrplot)

```

simulation Age/poids/clairance 

```{r}


#### girls



set.seed(2345)
gen_1 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=8.3, b=13.3, mean = 10.93, sd = 3))}
W_1 <- 1:1 %>% map_df(gen_1)%>% dplyr::mutate(age=1) 

set.seed(2345)
taille_1 <-  function (x) {tibble(ID1 = x, taille= rtruncnorm(300, a=68, b=95, mean = 83, sd = 3))}
T_1 <- 1:1 %>% map_df(taille_1)

W_1 <- W_1 %>% bind_cols(T_1) %>% select(Pds,taille,age)
summary(W_1)


set.seed(2345)
gen_2 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=10, b=18, mean =13.3, sd = 3.5))}
W_2 <- 1:1 %>% map_df(gen_2) %>% mutate(age=2)


set.seed(2345)
taille_2 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=82, b=100, mean = 90, sd = 3))}
T_2 <- 1:1 %>% map_df(taille_2)

W_2 <- W_2 %>% bind_cols(T_2) %>% select(Pds,taille,age)
summary(W_2)



Simu_inf2 <- W_1 %>% bind_rows(W_2) 
summary(Simu_inf2)



set.seed(2345)
gen_Clcreat <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(600, a=10, b=340, mean =90, sd = 250))}
Clcreat<- 1:1 %>% map_df(gen_Clcreat)

Simu_inf2 <- Simu_inf2 %>% bind_cols(Clcreat)
Simu_inf2 <- as.tibble(Simu_inf2 )%>% select(Pds,Clcreat,age,taille)%>% mutate(ID = 1:600)



set.seed(2345)
gen_3 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=12, b=20, mean =14.3, sd = 3.5))}
W_3 <- 1:1 %>% map_df(gen_3) %>% mutate(age=3)


set.seed(2345)
taille_3 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=88, b=110, mean = 98, sd = 3))}
T_3 <- 1:1 %>% map_df(taille_3)

W_3 <- W_3 %>% bind_cols(T_3) %>% select(Pds,taille,age)


set.seed(2345)
gen_4 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=12.4, b=23.3, mean =15.3, sd = 3.5))}
W_4<- 1:1 %>% map_df(gen_4) %>% mutate(age=4)

 
set.seed(2345)
taille_4 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=93, b=120, mean = 118, sd = 3.5))}
T_4 <- 1:1 %>% map_df(taille_4)

W_4 <- W_4 %>% bind_cols(T_4)%>% select(Pds,taille,age)


set.seed(2345)
gen_5 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=14.2, b=29.7, mean =19.5, sd = 3.5))}
W_5<- 1:1 %>% map_df(gen_5) %>% mutate(age=5)

set.seed(2345)
taille_5 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=100, b=129, mean = 112, sd = 3.5))}
T_5 <- 1:1 %>% map_df(taille_5)

W_5 <- W_5 %>% bind_cols(T_5)%>% select(Pds,taille,age)


Simu3_5 <- W_3 %>% bind_rows( W_4) %>% bind_rows( W_5)
set.seed(2345)
gen_Clcreat3_5 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(900, a=10, b=340, mean =90, sd = 250))}
Clcreat3_5<- 1:1 %>% map_df(gen_Clcreat3_5)


Simu3_5 <- Simu3_5 %>% bind_cols(Clcreat3_5)
Simu3_5 <- as.tibble(Simu3_5) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=601:1500)




set.seed(2345)
gen_6 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=16, b=32, mean =22, sd = 3.5))}
W_6<- 1:1 %>% map_df(gen_6) %>% mutate(age=6)

set.seed(2345)
taille_6 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=104, b=134, mean = 124, sd = 3.5))}
T_6 <- 1:1 %>% map_df(taille_6)

W_6 <- W_6 %>% bind_cols(T_6)%>% select(Pds,taille,age)



set.seed(2345)
gen_7 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=18, b=38.3, mean =24, sd = 5.5))}
W_7<- 1:1 %>% map_df(gen_7) %>% mutate(age=7)
set.seed(2345)
taille_7 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=108, b=143, mean = 124, sd = 5.5))}
T_7 <- 1:1 %>% map_df(taille_7)

W_7 <- W_7 %>% bind_cols(T_7)%>% select(Pds,taille,age)


set.seed(2345)
gen_8 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=19, b=44, mean =28.2, sd = 6.5))}
W_8<- 1:1 %>% map_df(gen_8) %>% mutate(age=8)
set.seed(2345)
taille_8 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=108, b=152, mean = 137.7, sd = 6.5))}
T_8 <- 1:1 %>% map_df(taille_8)

W_8 <- W_8 %>% bind_cols(T_8)%>% select(Pds,taille,age)


set.seed(2345)
gen_9 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=21, b=49.5, mean =29.5, sd = 7.5))}
W_9<- 1:1 %>% map_df(gen_9) %>% mutate(age=9)
set.seed(2345)
taille_9 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=118, b=154, mean = 135, sd = 7.5))}
T_9 <- 1:1 %>% map_df(taille_9)

W_9 <- W_9 %>% bind_cols(T_9)%>% select(Pds,taille,age)


set.seed(2345)
gen_10 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=22, b=52, mean =323.5, sd = 7.5))}
W_10<- 1:1 %>% map_df(gen_10)  %>% mutate(age=10)
set.seed(2345)
taille_10 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=122, b=165, mean = 141, sd = 7.5))}
T_10 <- 1:1 %>% map_df(taille_10)

W_10 <- W_10 %>% bind_cols(T_10)%>% select(Pds,taille,age)



set.seed(2345)
gen_11 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=24.5, b=64.5, mean =40, sd = 7.5))}
W_11<- 1:1 %>% map_df(gen_11)  %>% mutate(age=11)

set.seed(2345)
taille_11 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=124, b=175, mean = 148, sd = 7.5))}
T_11 <- 1:1 %>% map_df(taille_11)

W_11 <- W_11 %>% bind_cols(T_11)%>% select(Pds,taille,age)


Simu6_11 <- W_6 %>% bind_rows(W_7)%>% bind_rows(W_8)%>% bind_rows(W_9)%>% bind_rows(W_10)%>% bind_rows(W_11)
set.seed(2345)
gen_Clcreat6_11 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(1800, a=10, b=340, mean =90, sd = 250))}
Clcreat6_11<- 1:1 %>% map_df(gen_Clcreat6_11)


Simu6_11 <- Simu6_11 %>% bind_cols(Clcreat6_11)
Simu6_11 <- as.tibble(Simu6_11) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=1501:3300)
summary(Simu6_11)

### on associe les autres ages 

set.seed(2345)
gen_12 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=28, b=75, mean =46.5, sd = 8.5))}
W_12<- 1:1 %>% map_df(gen_12) %>% mutate(age=12)
set.seed(2345)
taille_12 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=125, b=182, mean = 155, sd = 8.5))}
T_12 <- 1:1 %>% map_df(taille_12)

W_12 <- W_12 %>% bind_cols(T_12)%>% select(Pds,taille,age)



set.seed(2345)
gen_13 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=28, b=80, mean =48, sd = 9.5))}
W_13<- 1:1 %>% map_df(gen_13) %>% mutate(age=13)
set.seed(2345)
taille_13 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=132, b=180, mean = 152, sd = 9.5))}
T_13 <- 1:1 %>% map_df(taille_13)

W_13 <- W_13 %>% bind_cols(T_13)%>% select(Pds,taille,age)


set.seed(2345)
gen_14 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=33, b=86, mean =50, sd = 10.5))}
W_14<- 1:1 %>% map_df(gen_14) %>% mutate(age=14)
set.seed(2345)
taille_14 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=140, b=190, mean = 165, sd = 10.5))}
T_14 <- 1:1 %>% map_df(taille_14)

W_14 <- W_14 %>% bind_cols(T_14)%>% select(Pds,taille,age)


set.seed(2345)
gen_15 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=36, b=92, mean =55, sd = 10.5))}
W_15<- 1:1 %>% map_df(gen_15) %>% mutate(age=15)
set.seed(2345)
taille_15 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 165, sd = 10.5))}
T_15 <- 1:1 %>% map_df(taille_15)

W_15 <- W_15 %>% bind_cols(T_15)%>% select(Pds,taille,age)


set.seed(2345)
gen_16 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=40, b=95, mean =57, sd = 10.5))}
W_16<- 1:1 %>% map_df(gen_16) %>% mutate(age=16)
set.seed(2345)
taille_16 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 165, sd = 10.5))}
T_16 <- 1:1 %>% map_df(taille_16)

W_16 <- W_16 %>% bind_cols(T_16)%>% select(Pds,taille,age)



set.seed(2345)
gen_17 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=43, b=99, mean =59, sd = 10.5))}
W_17<- 1:1 %>% map_df(gen_17) %>% mutate(age=17)
set.seed(2345)
taille_17 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 165, sd = 10.5))}
T_17 <- 1:1 %>% map_df(taille_17)

W_17 <- W_17 %>% bind_cols(T_17)%>% select(Pds,taille,age)



set.seed(2345)
gen_18 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=43, b=99, mean =59, sd = 10.5))}
W_18<- 1:1 %>% map_df(gen_18) %>% mutate(age=18)
set.seed(2345)
taille_18 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 165, sd = 10.5))}
T_18 <- 1:1 %>% map_df(taille_18)

W_18 <- W_18 %>% bind_cols(T_18)%>% select(Pds,taille,age)




simu12_18 <- W_12 %>% bind_rows(W_13) %>% bind_rows(W_14) %>% bind_rows(W_15) %>% bind_rows(W_16) %>% bind_rows(W_17) %>% bind_rows(W_18)
set.seed(2345)
gen_Clcreat12_18 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(2100, a=10, b=340, mean =90, sd = 250))}
Clcreat12_18<- 1:1 %>% map_df(gen_Clcreat12_18)


simu12_18 <- simu12_18 %>% bind_cols(Clcreat12_18)
Simu12_18 <- as.tibble(simu12_18) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=3301:5400)

summary(Simu12_18)


Simu_totale_fille <- Simu_inf2 %>% bind_rows(Simu3_5)%>% bind_rows(Simu6_11)%>% bind_rows(simu12_18) %>% select(Pds,Clcreat,age,taille)%>% mutate(ID=c(1:5400))%>% mutate(SEX="fille")
summary(Simu_totale_fille)


###  boys 



set.seed(2345)
gen_1 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=7.3, b=16.3, mean = 11.93, sd = 3))}
W_1 <- 1:1 %>% map_df(gen_1)%>% dplyr::mutate(age=1) 


set.seed(2345)
taille_1 <-  function (x) {tibble(ID1 = x, taille= rtruncnorm(300, a=72, b=95, mean = 83, sd = 3))}
T_1 <- 1:1 %>% map_df(taille_1)

W_1 <- W_1 %>% bind_cols(T_1) %>% select(Pds,taille,age)
summary(W_1)


set.seed(2345)
gen_2 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=9.5, b=20, mean =13.8, sd = 3.5))}
W_2 <- 1:1 %>% map_df(gen_2) %>% mutate(age=2)

set.seed(2345)
taille_2 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=79, b=108, mean = 92, sd = 3))}
T_2 <- 1:1 %>% map_df(taille_2)

W_2 <- W_2 %>% bind_cols(T_2) %>% select(Pds,taille,age)
summary(W_2)



Simu_inf2 <- W_1 %>% bind_rows(W_2) 
summary(Simu_inf2)



set.seed(2345)
gen_Clcreat <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(600, a=10, b=340, mean =90, sd = 250))}
Clcreat<- 1:1 %>% map_df(gen_Clcreat)

Simu_inf2 <- Simu_inf2 %>% bind_cols(Clcreat)
Simu_inf2 <- as.tibble(Simu_inf2 )%>% select(Pds,Clcreat,age,taille)%>% mutate(ID = 1:600)



set.seed(2345)
gen_3 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=11, b=22, mean =15.3, sd = 3.5))}
W_3 <- 1:1 %>% map_df(gen_3) %>% mutate(age=3)


set.seed(2345)
taille_3 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=86, b=118, mean = 100, sd = 3))}
T_3 <- 1:1 %>% map_df(taille_3)

W_3 <- W_3 %>% bind_cols(T_3) %>% select(Pds,taille,age)


set.seed(2345)
gen_4 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=12.4, b=25.3, mean =17.3, sd = 3.5))}
W_4<- 1:1 %>% map_df(gen_4) %>% mutate(age=4)

set.seed(2345)
taille_4 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=92, b=124, mean = 108, sd = 3.5))}
T_4 <- 1:1 %>% map_df(taille_4)

W_4 <- W_4 %>% bind_cols(T_4)%>% select(Pds,taille,age)


set.seed(2345)
gen_5 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=15, b=30, mean =19.8, sd = 3.5))}
W_5<- 1:1 %>% map_df(gen_5) %>% mutate(age=5)

set.seed(2345)
taille_5 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=98, b=137, mean = 115, sd = 3.5))}
T_5 <- 1:1 %>% map_df(taille_5)

W_5 <- W_5 %>% bind_cols(T_5)%>% select(Pds,taille,age)


Simu3_5 <- W_3 %>% bind_rows( W_4) %>% bind_rows( W_5)
set.seed(2345)
gen_Clcreat3_5 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(900, a=10, b=340, mean =90, sd = 250))}
Clcreat3_5<- 1:1 %>% map_df(gen_Clcreat3_5)


Simu3_5 <- Simu3_5 %>% bind_cols(Clcreat3_5)
Simu3_5 <- as.tibble(Simu3_5) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=601:1500)




set.seed(2345)
gen_6 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=15, b=30, mean =22, sd = 3.5))}
W_6<- 1:1 %>% map_df(gen_6) %>% mutate(age=6)

set.seed(2345)
taille_6 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=102, b=140, mean = 122, sd = 3.5))}
T_6 <- 1:1 %>% map_df(taille_6)

W_6 <- W_6 %>% bind_cols(T_6)%>% select(Pds,taille,age)



set.seed(2345)
gen_7 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=17, b=35.3, mean =25, sd = 5.5))}
W_7<- 1:1 %>% map_df(gen_7) %>% mutate(age=7)
set.seed(2345)
taille_7 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=108, b=145, mean = 125, sd = 5.5))}
T_7 <- 1:1 %>% map_df(taille_7)

W_7 <- W_7 %>% bind_cols(T_7)%>% select(Pds,taille,age)


set.seed(2345)
gen_8 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=19, b=48, mean =28, sd = 6.5))}
W_8<- 1:1 %>% map_df(gen_8) %>% mutate(age=8)
set.seed(2345)
taille_8 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=112, b=152, mean = 132, sd = 6.5))}
T_8 <- 1:1 %>% map_df(taille_8)

W_8 <- W_8 %>% bind_cols(T_8)%>% select(Pds,taille,age)



set.seed(2345)
gen_9 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=21, b=49.5, mean =29.5, sd = 7.5))}
W_9<- 1:1 %>% map_df(gen_9) %>% mutate(age=9)
set.seed(2345)
taille_9 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=116, b=160, mean = 138, sd = 7.5))}
T_9 <- 1:1 %>% map_df(taille_9)

W_9 <- W_9 %>% bind_cols(T_9)%>% select(Pds,taille,age)


set.seed(2345)
gen_10 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=23, b=62, mean =33.5, sd = 7.5))}
W_10<- 1:1 %>% map_df(gen_10)  %>% mutate(age=10)
set.seed(2345)
taille_10 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=120, b=165, mean = 142, sd = 7.5))}
T_10 <- 1:1 %>% map_df(taille_10)

W_10 <- W_10 %>% bind_cols(T_10)%>% select(Pds,taille,age)



set.seed(2345)
gen_11 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=24.5, b=69.5, mean =38, sd = 7.5))}
W_11<- 1:1 %>% map_df(gen_11)  %>% mutate(age=11)

set.seed(2345)
taille_11 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=125, b=173, mean = 148, sd = 7.5))}
T_11 <- 1:1 %>% map_df(taille_11)

W_11 <- W_11 %>% bind_cols(T_11)%>% select(Pds,taille,age)


Simu6_11 <- W_6 %>% bind_rows(W_7)%>% bind_rows(W_8)%>% bind_rows(W_9)%>% bind_rows(W_10)%>% bind_rows(W_11)
set.seed(2345)
gen_Clcreat6_11 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(1800, a=10, b=340, mean =90, sd = 250))}
Clcreat6_11<- 1:1 %>% map_df(gen_Clcreat6_11)


Simu6_11 <- Simu6_11 %>% bind_cols(Clcreat6_11)
Simu6_11 <- as.tibble(Simu6_11) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=1501:3300)
summary(Simu6_11)

### on associe les autres ages 

set.seed(2345)
gen_12 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=26, b=80, mean =42, sd = 8.5))}
W_12<- 1:1 %>% map_df(gen_12) %>% mutate(age=12)
set.seed(2345)
taille_12 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=128, b=182, mean = 155, sd = 8.5))}
T_12 <- 1:1 %>% map_df(taille_12)

W_12 <- W_12 %>% bind_cols(T_12)%>% select(Pds,taille,age)



set.seed(2345)
gen_13 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=28, b=80, mean =48, sd = 9.5))}
W_13<- 1:1 %>% map_df(gen_13) %>% mutate(age=13)
set.seed(2345)
taille_13 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=132, b=190, mean = 161, sd = 9.5))}
T_13 <- 1:1 %>% map_df(taille_13)

W_13 <- W_13 %>% bind_cols(T_13)%>% select(Pds,taille,age)


set.seed(2345)
gen_14 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=33, b=92, mean =55, sd = 10.5))}
W_14<- 1:1 %>% map_df(gen_14) %>% mutate(age=14)
set.seed(2345)
taille_14 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=136, b=195, mean = 177, sd = 10.5))}
T_14 <- 1:1 %>% map_df(taille_14)

W_14 <- W_14 %>% bind_cols(T_14)%>% select(Pds,taille,age)


set.seed(2345)
gen_15 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=36, b=92, mean =60, sd = 10.5))}
W_15<- 1:1 %>% map_df(gen_15) %>% mutate(age=15)
set.seed(2345)
taille_15 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 172, sd = 10.5))}
T_15 <- 1:1 %>% map_df(taille_15)

W_15 <- W_15 %>% bind_cols(T_15)%>% select(Pds,taille,age)


set.seed(2345)
gen_16 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=40, b=95, mean =62, sd = 10.5))}
W_16<- 1:1 %>% map_df(gen_16) %>% mutate(age=16)
set.seed(2345)
taille_16 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 175, sd = 10.5))}
T_16 <- 1:1 %>% map_df(taille_16)

W_16 <- W_16 %>% bind_cols(T_16)%>% select(Pds,taille,age)



set.seed(2345)
gen_17 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=43, b=110, mean =65, sd = 10.5))}
W_17<- 1:1 %>% map_df(gen_17) %>% mutate(age=17)
set.seed(2345)
taille_17 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=154, b=195, mean = 175, sd = 10.5))}
T_17 <- 1:1 %>% map_df(taille_17)

W_17 <- W_17 %>% bind_cols(T_17)%>% select(Pds,taille,age)



set.seed(2345)
gen_18 <-  function (x) {tibble(ID1 = x, Pds= rtruncnorm(300, a=43, b=99, mean =65, sd = 10.5))}
W_18<- 1:1 %>% map_df(gen_18) %>% mutate(age=18)
set.seed(2345)
taille_18 <-  function (x) {tibble(ID1 = x, taille = rtruncnorm(300, a=144, b=195, mean = 175, sd = 10.5))}
T_18 <- 1:1 %>% map_df(taille_18)

W_18 <- W_18 %>% bind_cols(T_18)%>% select(Pds,taille,age)




simu12_18 <- W_12 %>% bind_rows(W_13) %>% bind_rows(W_14) %>% bind_rows(W_15) %>% bind_rows(W_16) %>% bind_rows(W_17) %>% bind_rows(W_18)
set.seed(2345)
gen_Clcreat12_18 <-  function (x) {tibble(ID1 = x, Clcreat= rtruncnorm(2100, a=10, b=340, mean =90, sd = 250))}
Clcreat12_18<- 1:1 %>% map_df(gen_Clcreat12_18)


simu12_18 <- simu12_18 %>% bind_cols(Clcreat12_18)
Simu12_18 <- as.tibble(simu12_18) %>% select(Pds,Clcreat,age,taille)%>% mutate (ID=3301:5400)

summary(Simu12_18)






Simu_totale_boy<- Simu_inf2 %>% bind_rows(Simu3_5)%>% bind_rows(Simu6_11)%>% bind_rows(simu12_18) %>% select(Pds,Clcreat,age,taille)%>% mutate(ID=c(1:5400))%>% mutate(SEX="garcon")
summary(Simu_totale_boy)





Simu_totale <- Simu_totale_boy %>% bind_rows(Simu_totale_fille) %>% select(-ID)%>% mutate(ID=c(1:10800))


Simu_totale <- Simu_totale %>% mutate(SC_mosteller= sqrt((taille*Pds)/3600))
summary(Simu_totale)

#### type of transplantation

Simu_totale<- Simu_totale %>% mutate(type_greffe= sample(1:2,10800,replace=T))
Simu_totale$type_greffe=as.factor(Simu_totale$type_greffe)


Simu_totale<- Simu_totale %>% mutate(greffe= case_when(type_greffe=="1"~"solide",type_greffe=="2"~"moelle" ))%>% select(-type_greffe)
#
                                      

### guidelines doses 

Simu_totale_avec_dose2 <- Simu_totale %>% mutate (Clcreat2 = case_when(Clcreat<150 ~ Clcreat, Clcreat>=150 ~ 150))%>%mutate(amt= 7*SC_mosteller*Clcreat2)%>% mutate(amt2 = case_when(amt<900 ~ amt, amt>=900 ~ 900))


                                                             
summary(Simu_totale_avec_dose2)

set.seed(123)  
sample <- sample.int(n = nrow(Simu_totale_avec_dose2), size = floor(.25*nrow(Simu_totale_avec_dose2)), replace = F)

data_bene <- Simu_totale_avec_dose2[sample, ]
Simu_totale_avec_dose2_2  <- Simu_totale_avec_dose2[-sample, ]


set.seed(123)  
sample2 <- sample.int(n = nrow(Simu_totale_avec_dose2_2), size = floor(.33*nrow(Simu_totale_avec_dose2_2)), replace = F)

data_nguyen <- Simu_totale_avec_dose2_2[sample2, ]
Simu_totale_avec_dose2_3  <- Simu_totale_avec_dose2_2[-sample2, ]


set.seed(123)  
sample3 <- sample.int(n = nrow(Simu_totale_avec_dose2_3), size = floor(.50*nrow(Simu_totale_avec_dose2_3)), replace = F)

data_pescovitz <- Simu_totale_avec_dose2_3[sample3, ]
Simu_totale_avec_dose2_4  <- Simu_totale_avec_dose2_3[-sample3, ]


set.seed(123)  
sample4 <- sample.int(n = nrow(Simu_totale_avec_dose2_4), size = floor(1*nrow(Simu_totale_avec_dose2_4)), replace = F)

data_Facchin <- Simu_totale_avec_dose2_4[sample4, ]
Simu_totale_avec_dose2_5  <- Simu_totale_avec_dose2_4[-sample4, ]










```
Franck Model

```{r}
code_bene <- "

[PROB] #modèle Ganciclovir bjcp Franck et al 2020

[SET] end=100, delta=0.1

[PARAM] @annotated


TVKa: 0.73 : typical Ka (/h)
TVF:  0.43: Typical bioavailability (%)
TV1: 9.7 :  typical V1
TV2: 7.6:  typical  V2
TVQ : 10.9 : typical intercompartmental clearance
TVCL : 6.9 : typical CL 
WT :26.7 : median current weight 
CLCREA :148.8: median Cl creat 
CrCL: 0.88 : effet of CrCL on CL


[CMT] @annotated
DEPOT  : Dosing compartment (mg)
CENT : Central compartment
PERI : First peripheral compartment 
 

 [OMEGA] @annotated
ETACL : 0.19 : ETA on clearance
ETAV1 : 0.348 : ETA on V1
ETAKa : 0.49 : ETA on Ka
ETAF : 0.096 : ETA on F 

[MAIN]

double Ka = TVKa*exp(ETAKa);
double CL = TVCL*pow(WT/26.7,0.75)*pow(CLCREA/148.8,CrCL)*exp(ETACL);
double Q = TVQ ;
double V1 = (TV1*WT/26.5)*exp(ETAV1) ;
double V2 = TV2*WT/26.5 ;
F_DEPOT= TVF*exp(ETAF);
ALAG_DEPOT = 0.33;



[SIGMA] @annotated
ADD : 0.01 : additive Residual unexplained variability 0.98


[ODE]
dxdt_DEPOT = -Ka*DEPOT;
dxdt_CENT = Ka*DEPOT -(CL+Q)*CENT/V1 + Q*PERI/V2 ;
dxdt_PERI = Q*CENT/V1 - Q*PERI/V2 ;

[TABLE] 
capture CP = (CENT/V1)+ADD;
int i = 0;
while(CP<0 && i <100) {
simeps(1);
CP = (CENT/V1) + EPS(1);
++i;
}

"


my_model_bene <- mcode("ganciclovir_model", code_bene)


my_model_bene %>% 
  ev(am = 520 ,ss=1, ii=12) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()

my_model_bene %>% 
  ev(am = 520 ,ss=1, ii=12) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()


data <- expand.ev(ID = 1:10, amt = 520,ii=24, ss=1)#) #2,2.5,3, 3.5, 4
set.seed(2345)
sim_bene <- my_model_bene %>% 
  data_set(data) %>%
  Req(CP) %>%
 mrgsim(delta = 1, end = 24)#%>% 
  #f#ilter(time==24)
  #plot()
  #filter(time==23.9)







```
pescovitz Model

```{r}
code_pescovitz <- "

[PROB] #modèle GanciclovirTransplant Infectious Disease Pescovitz et al 2009

[SET] end=100, delta=0.1

[PARAM] @annotated


TVKa: 0.42 : typical Ka (/h)
TVF:  0.55: Typical bioavailability (%)
TV1: 20 :  typical V1
TV2: 15:  typical  V2
TVQ : 8 : typical intercompartmental clearance
TVCL : 5.4 : etypical CL 
TVALAG:0.22: typical lag time
WT :26.7 : median current weight 
CLCREA :148.8: median Cl creat 


[CMT] @annotated
DEPOT  : Dosing compartment (mg)
CENT : Central compartment
PERI : First peripheral compartment 
 

 [OMEGA] @annotated
ETACL : 0.0029 : ETA on clearance
ETAlag: 0.001936:ETA on lagtime
ETAV1 : 0.0036 : ETA on V1
ETAV2 : 0.0045 : ETA on V2
ETAKa : 0.0256 : ETA on Ka
ETAQ: 0.0361: ETA on Q
ETAF : 0.0047 : ETA on F 

[MAIN]

double Ka = TVKa*exp(ETAKa);
double CL = TVCL*exp(ETACL);
double Q = TVQ*exp(ETAQ) ;
double V1 = TV1*exp(ETAV1) ;
double V2 = TV2*exp(ETAV1)  ;
F_DEPOT= TVF*exp(ETAF);
ALAG_DEPOT= TVALAG*exp(ETAlag);
 

[SIGMA] @annotated
PROP: 0.001: proportionnel error 0.29
ADD : 0.001 : additive Residual unexplained variability 0.14

[ODE]
dxdt_DEPOT = -Ka*DEPOT;
dxdt_CENT = Ka*DEPOT -(CL+Q)*CENT/V1 + Q*PERI/V2 ;
dxdt_PERI = Q*CENT/V1 - Q*PERI/V2 ;

[TABLE] 

capture CP = (CENT/V1)*(1+ EPS(1)) + EPS(2) ;
int i = 0;
while(CP<0 && i <100) {
simeps();
CP = (CENT/V1)*(1+ EPS(1)) + EPS(2) ;
++i;
}

"


my_model_pescovitz <- mcode("ganciclovir_model_pescovitz", code_pescovitz)


my_model_pescovitz %>% 
  ev(am = 600 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()

my_model_pescovitz %>% 
  ev(am = 520 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()


data <- expand.ev(ID = 1:10, amt = 520,ii=24, ss=1)#) #2,2.5,3, 3.5, 4
set.seed(2345)
sim_pescovitz <- my_model_pescovitz %>% 
  data_set(data) %>%
  Req(CP) %>%
 mrgsim(delta = 1, end = 24)#%>% 
  #filter(time==24)
  #plot()
  #filter(time==23.9)




```
 NGuyen model

```{r}
code_nguyen <- "

[PROB] #modèle Ganciclovir  Nguyen et al 2021

[SET] end=100, delta=0.1

[PARAM] @annotated


TVKa: 0.506 : typical Ka (/h)
TVF:  0.438: Typical bioavailability (%)
TV1: 5.96 :  typical V1
TV2: 1.29:  typical  V2
TVQ : 0.222 : typical intercompartmental clearance
TVCL : 2.55 : etypical CL 
CRCL : 0.763 : effect ClCr deviation on CL 
WT :26.7 : median current weight 
CLCREA :148.8: median Cl creat 


[CMT] @annotated
DEPOT  : Dosing compartment (mg)
CENT : Central compartment
PERI : First peripheral compartment 
 

[OMEGA] @annotated
ETACL : 0.0556 : ETA on clearance
ETAV1 : 0.0484 : ETA on V1



[MAIN]
 

double Ka = TVKa;
double CL = TVCL*pow(WT/11.7,0.75)*pow(CLCREA/167,CRCL)*exp(ETACL);
double Q = TVQ*pow(WT/11.7,0.75) ;
double V1 = TV1*pow(WT/11.7,1)*exp(ETAV1);
double V2 = TV2*pow(WT/11.7,1) ;
F_DEPOT= TVF;




[SIGMA] @annotated
PROP: 0.001: proportionnel error 0.477

[ODE]
dxdt_DEPOT = -Ka*DEPOT;
dxdt_CENT = Ka*DEPOT -(CL+Q)*CENT/V1 + Q*PERI/V2 ;
dxdt_PERI = Q*CENT/V1 - Q*PERI/V2 ;

[TABLE] 
capture CP = (CENT/V1)* (1+ EPS(1));
int i = 0;
while(CP<0 && i <100) {
simeps();
CP = (CENT/V1)* (1+ EPS(1)) ;
++i;
}

"


my_model_nguyen <- mcode("ganciclovir_model_nguyen", code_nguyen)


my_model_nguyen %>% 
  ev(am = 520 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()

my_model_nguyen %>% 
  ev(am = 520 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()


data <- expand.ev(ID = 1:10, amt = 520,ii=12, ss=1)#) #2,2.5,3, 3.5, 4
set.seed(2345)
sim_nguyen <- my_model_nguyen %>% 
  data_set(data) %>%
  Req(CP) %>%
 mrgsim(delta = 1, end = 24)#%>% 
  #filter(time==12)
  #plot()
  #filter(time==23.9)




```
 Facchin Model

```{r}
code_Facchin <- "

[PROB] #modèle Facchin et al 2009 

[SET] end=100, delta=0.1

[PARAM] @annotated


TVKa: 6.96 : typical Ka (/h)
TVALAG:0.86: typical lag time
TV1: 45 :  typical V1
TV2: 18.5:  typical  V2
TVQ : 1.46 : typical intercompartmental clearance
TVCL:9.07 : clearance typique 
CRCL : -0.768 : effect Creat deviation on CL 
CRBSA: 1.31: effet BSA on cl
VBSA: 1.28: effet BSA on V 
CRSEX:1.15 : effet sexe on cl 
VSEX: 1.14: effet SEX on V 
BSA :1.08  : median BSA
CREA :72.5: median creat 
SEX : 1 : 1 si garçon 0 si fille 


[CMT] @annotated
DEPOT  : Dosing compartment (mg)
CENT : Central compartment
PERI : First peripheral compartment 
 

 [OMEGA] @annotated
ETACL :0.0256 : ETA on clearance
ETAV1 : 0.0086 : ETA on V1
ETAV2 : 0.298 : ETA on V2
ETAKa : 0.350 : ETA on Ka



[MAIN]
 

double Ka = TVKa*exp(ETAKa);
double CL = TVCL*pow(BSA,CRBSA)*pow(CREA/72.5,CRCL)*pow(CRSEX,SEX)*exp(ETACL);
double Q = TVQ ;
double V1 = TV1*pow(BSA,VBSA)*pow(VSEX,SEX)*exp(ETAV1);
double V2 = TV2*exp(ETAV2) ;
ALAG_DEPOT= TVALAG;



[SIGMA] @annotated
ADD: 0.01: additive error log(0.23)

[ODE]
dxdt_DEPOT = -Ka*DEPOT;
dxdt_CENT = Ka*DEPOT -(CL+Q)*CENT/V1 + Q*PERI/V2 ;
dxdt_PERI = Q*CENT/V1 - Q*PERI/V2 ;

[TABLE] 
capture CP = (CENT/V1)+ EPS(1);
int i = 0;
while(CP<0 && i <100) {
simeps();
CP = (CENT/V1)+ EPS(1);
++i;
}

"


my_model_Facchin <- mcode("ganciclovir_model_Facchin", code_Facchin)


my_model_Facchin %>% 
  ev(am = 400 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()

my_model_Facchin %>% 
  ev(am = 600 ,ss=1, ii=24) %>%
  Req(CP) %>%
  mrgsim(delta = 0.1, end = 24) %>% 
  plot()


data <- expand.ev(ID = 1:10, amt = 520,ii=24, ss=1)#) #2,2.5,3, 3.5, 4
set.seed(2345)
sim_Facchin <- my_model_Facchin %>% 
  data_set(data) %>%
  Req(CP) %>%
 mrgsim(delta = 1, end = 24)#%>% 
  #filter(time==12)
  #plot()
  #filter(time==23.9)




```

```{r}

### model Franck

e_bene <- expand.ev( ii = 24, ID=1:2700,addl = 5,ss=1) %>%  select(-amt) %>% bind_cols(data_bene)%>% mutate(ID=1:2700)%>%  select(-ID...1,-amt)%>% rename(amt=amt2)


summary(e_bene)

out <- my_model_bene %>% 
  data_set(e_bene) %>%
  Req(CP) %>%
  mrgsim(end = 120, delta = 0.5)

out_bene <- as_tibble(out) %>% left_join(e_bene, by = "ID") %>% filter(CP>0)  

summary(out_bene)

library(PKNCA)


#AUC calcul
auc_trap_bene <- out_bene %>% select(ID,time.x,CP,ii,addl,evid,cmt,amt,ID)%>% rename(dose =amt,OUT=CP,TIME=time.x) %>%
filter(between(TIME,24,48))


data.conc <-PKNCAconc(auc_trap_bene,OUT~TIME|ID)


data_obj <- PKNCAdata(data.conc=data.conc,
                      intervals=data.frame(start=24,
                                           end=48,
                                           aucall=F,
                                           auclast=TRUE,
                                           aucinf.pred=F,
                                           aucinf.obs=F))
results_obj <- pk.nca(data_obj)$result


trap1 <- results_obj %>% dplyr::select(ID, trap =PPORRES) %>% mutate(auc = round(trap,5))%>% dplyr::select(-trap)


simu_auc_bene <-left_join(out_bene,trap1) %>% mutate(methode="bene")
summary(simu_auc_bene)





#### facchin

e_Facchin <- expand.ev( ii = 24, ID=2701:5414,addl = 5,ss=1) %>%  select(-amt) %>% bind_cols(data_Facchin)%>% mutate(ID=2701:5414)%>%  select(-ID...1,-amt)%>% rename(amt=amt2) %>% mutate(SEX2 = case_when(SEX== "fille"~ "0",SEX== "garcon"~ "1" ))%>% select(-SEX) %>% rename (SEX=SEX2) %>% mutate(BSA=SC_mosteller) %>% mutate (CRE= case_when(age<12~49*taille/Clcreat, age>=12 & SEX <1 ~ 53*taille/Clcreat,age>=12 & SEX>=1 ~ 62*taille/Clcreat ))%>% mutate (CREA = case_when(CRE<350 ~ CRE, CRE>=350 ~ 350))

e_Facchin$SEX=as.numeric(e_Facchin$SEX)
summary(e_Facchin)

out_Facchin <- my_model_Facchin %>% 
  data_set(e_Facchin) %>%
  Req(CP) %>%
  mrgsim(end = 120, delta = 0.5)

out_Facchin <- as_tibble(out_Facchin) %>% left_join(e_Facchin, by = "ID") %>% filter(CP>0)  

summary(out_Facchin)

library(PKNCA)


# AUC 
auc_trap_Facchin <- out_Facchin  %>% select(ID,time.x,CP,ii,addl,evid,cmt,amt,ID)%>% rename(dose =amt,OUT=CP,TIME=time.x) %>%
filter(between(TIME,24,48))


data.conc <-PKNCAconc(auc_trap_Facchin,OUT~TIME|ID)


data_obj <- PKNCAdata(data.conc=data.conc,
                      intervals=data.frame(start=24,
                                           end=48,
                                           aucall=F,
                                           auclast=TRUE,
                                           aucinf.pred=F,
                                           aucinf.obs=F))

results_obj <- pk.nca(data_obj)$result


trap1 <- results_obj %>% dplyr::select(ID, trap =PPORRES) %>% mutate(auc = round(trap,5))%>% dplyr::select(-trap)


simu_auc_Facchin<-left_join(out_Facchin ,trap1)%>% mutate(methode="Facchin")
summary(simu_auc_Facchin)

#### simu avec  pescovitz

e_pescovitz <- expand.ev( ii = 24, ID=5414:8126,addl = 5,ss=1) %>%  select(-amt) %>% bind_cols(data_pescovitz)%>% mutate(ID=5414:8126)%>%  select(-ID...1,-amt)%>% rename(amt=amt2)


summary(e_pescovitz)

out_pescovitz <- my_model_pescovitz %>% 
  data_set(e_pescovitz) %>%
  Req(CP) %>%
  mrgsim(end = 120, delta = 0.5)

out_pescovitz <- as_tibble(out_pescovitz) %>% left_join(e_pescovitz, by = "ID") %>% filter(CP>0)  

summary(out_pescovitz)

library(PKNCA)


# AUC 
auc_trap_pescovitz <- out_pescovitz  %>% select(ID,time.x,CP,ii,addl,evid,cmt,amt,ID)%>% rename(dose =amt,OUT=CP,TIME=time.x) %>%
filter(between(TIME,24,48))


data.conc <-PKNCAconc(auc_trap_pescovitz,OUT~TIME|ID)


data_obj <- PKNCAdata(data.conc=data.conc,
                      intervals=data.frame(start=24,
                                           end=48,
                                           aucall=F,
                                           auclast=TRUE,
                                           aucinf.pred=F,
                                           aucinf.obs=F))
results_obj <- pk.nca(data_obj)$result


trap1 <- results_obj %>% dplyr::select(ID, trap =PPORRES) %>% mutate(auc = round(trap,5))%>% dplyr::select(-trap)


simu_auc_pescovitz <-left_join(out_pescovitz ,trap1)%>% mutate(methode="Pescovitz")
summary(simu_auc_pescovitz )

####  simulation nguyen

e_nguyen <- expand.ev( ii = 24, ID=8127:10799,addl = 5,ss=1) %>%  select(-amt) %>% bind_cols(data_nguyen)%>% mutate(ID=8127:10799)%>%  select(-ID...1,-amt)%>% rename(amt=amt2) 


summary(e_nguyen)

out_nguyen <- my_model_nguyen %>% 
  data_set(e_nguyen) %>%
  Req(CP) %>%
  mrgsim(end = 120, delta = 0.5)

out_nguyen <- as_tibble(out_nguyen) %>% left_join(e_nguyen, by = "ID") %>% filter(CP>0)  

summary(out_nguyen)

library(PKNCA)


#AUC 
auc_trap_nguyen<- out_nguyen  %>% select(ID,time.x,CP,ii,addl,evid,cmt,amt,ID)%>% rename(dose =amt,OUT=CP,TIME=time.x) %>%
filter(between(TIME,24,48))


data.conc <-PKNCAconc(auc_trap_nguyen,OUT~TIME|ID)


data_obj <- PKNCAdata(data.conc=data.conc,
                      intervals=data.frame(start=24,
                                           end=48,
                                           aucall=F,
                                           auclast=TRUE,
                                           aucinf.pred=F,
                                           aucinf.obs=F))
results_obj <- pk.nca(data_obj)$result


trap1 <- results_obj %>% dplyr::select(ID, trap =PPORRES) %>% mutate(auc = round(trap,5))%>% dplyr::select(-trap)


simu_auc_nguyen<-left_join(out_nguyen ,trap1)%>% mutate(methode="nguyen")
summary(simu_auc_nguyen)




#### on remet les SEX en garcon fille pour Facchin
simu_auc_Facchin$SEX=as.factor(simu_auc_Facchin$SEX)
summary(simu_auc_Facchin)
simu_auc_Facchin<- simu_auc_Facchin%>% mutate(SEX2 = case_when(SEX== "0"~ "fille",SEX== "1"~ "garcon" ))%>% select(-SEX)%>% rename (SEX=SEX2)

simu_auc_Facchin$SEX=as.factor(simu_auc_Facchin$SEX)

simu_auc <- bind_rows(simu_auc_Facchin)%>% bind_rows(simu_auc_bene)%>% bind_rows(simu_auc_nguyen)%>% bind_rows(simu_auc_pescovitz)
summary(simu_auc)
#hist(simu_auc$auc)
#quantile(simu_auc$auc, c(0.05, 0.5, 0.95))

auc <- simu_auc %>%
        filter(time.x==48)%>%  filter(auc <= 110 & auc>=5 )



summary(auc)

#auc_final <- auc %>% select(ID,Pds, Clcreat,age,taille,amt,auc,SEX,methode,greffe,Clcreat2)



```


```{r}




simu_auc_Facchin <- simu_auc_Facchin %>% select(ID,time.x,CP,Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,auc,methode)%>% mutate(dose=amt)
#quantile(simu_auc_Facchin$auc, c(0.05, 0.5, 0.95))




simu_auc_bene <- simu_auc_bene %>% select(ID,time.x,CP,Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,auc,methode)%>% mutate(dose=amt)
#quantile(simu_auc_bene$auc, c(0.05, 0.5, 0.95))

simu_auc_pescovitz <- simu_auc_pescovitz %>% select(ID,time.x,CP,Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,auc,methode)%>% mutate(dose=amt)

simu_auc_nguyen <- simu_auc_nguyen %>% select(ID,time.x,CP,Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,auc,methode)%>% mutate(dose=amt)


simu_auc <- simu_auc_Facchin%>% bind_rows(simu_auc_bene)%>% bind_rows(simu_auc_nguyen)%>% bind_rows(simu_auc_pescovitz)

summary(simu_auc )

simu_auc <- simu_auc %>% 
  mutate(time_bin = factor(case_when(time.x  < 0.1 ~ "out_0",
         between(time.x ,0.1,0.6)~"out_0.5",
         between(time.x ,0.7, 1.1) ~"out_1",
         between(time.x ,1.2, 1.7) ~"out_1.5",
         between(time.x ,1.8, 2.3) ~"out_2",
         between(time.x ,2.3, 2.7) ~"out_2.5",
         between(time.x ,2.8, 3.3) ~"out_3",
         between(time.x ,3.4, 3.7) ~"out_3.5",
         between(time.x ,3.8, 4.4) ~"out_4",
         between(time.x ,4.9, 5.4) ~"out_5",
         between(time.x ,5.9, 6.4) ~"out_6",
         between(time.x ,6.9, 7.4) ~"out_7",
         between(time.x ,7.9, 8.4) ~"out_8",
         between(time.x ,8.9, 9.4) ~"out_9",
         between(time.x ,9.9, 10.4) ~"out_10",
         between(time.x ,11.9, 12.4) ~"out_12", 
         between(time.x ,13.9, 14.4) ~"out_14", 
         between(time.x ,15.9, 16.4) ~"out_16", 
         between(time.x ,17.9, 18.4) ~"out_18",
         between(time.x ,19.8, 20.4) ~"out_20",
         between(time.x ,23.9, 24.4) ~"out_24")))
 
auc <- simu_auc %>% ungroup %>% pivot_wider(id_cols=c(ID,Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,auc),names_from =  time_bin ,values_from = CP,values_fn=mean,names_repair="minimal")

summary(auc)

quantile(auc$auc, c(0.05, 0.5, 0.95))
auc <-auc %>%  filter(auc <= 110 & auc>=5 )



```

```{r}
library(tidymodels)

set.seed(1234)
auc_1<- auc %>% dplyr::select( -ID,-"NA")
summary(auc_1)
```

```{r}
library(tidymodels)
auc_1_bis<- auc_1%>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_0,out_1,out_2,out_3,out_4,out_6,auc)
set.seed(123)

splits <- initial_split(auc_1_bis, strata = auc)
auc_train <- training(splits)
auc_test  <- testing(splits)

set.seed(234)
auc_set <- validation_split(auc_train, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train <- analysis(auc_set$splits[[1]])
auc_train_test <-assessment(auc_set$splits[[1]])
```

```{r}
auc_rec <- recipe(auc ~ ., data = auc_train_train) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe <-  prep(auc_rec)
auc_train_recipe <-juice(auc_prep_recipe)
summary(auc_train_recipe)



```
on commence avec glmnet

```{r}
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds <- vfold_cv(auc_train_train, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet <- tune_grid(
  glmnet_wf,
  resamples = auc_folds,
  grid = 30)


tune_glmnet%>% collect_metrics()

best_rmse_glmnet <- select_best(tune_glmnet, "rmse",  maximize = F)
final_glmnet <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet
)

final_glmnet


library(vip)

#finalize workflow
final_wf_glmnet <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(final_glmnet)

###resample#####
set.seed(456)
folds <- vfold_cv(auc_train_train)#par défaut 10 fois
set.seed(123)
glmnet_rs <- fit_resamples(object = final_wf_glmnet, resamples = folds, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs %>% collect_metrics()

pred_obs_glmnet <- glmnet_rs %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet$bias_rel)
sqrt(mean(pred_obs_glmnet$bias_rel_square))

glmnet_rs %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

```

Xgboost

```{r}
# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds <- vfold_cv(auc_train_train)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf,
  resamples = auc_folds,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb<- finalize_model(
  xgb_spec,
  best_rmse_xgb
)

final_xgb

vip_plt <-final_xgb %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe)
  ) %>%
  vip::vip(geom = "col")
vip_plt
#finalize workflow
final_wf_xgb <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(final_xgb)%>%
  fit(auc_train_train)

###resample#####
set.seed(456)
folds <- vfold_cv(auc_train_train)#par défaut 10 fois
set.seed(123)
xgb_rs <- fit_resamples(object = final_wf_xgb, resamples = folds, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs %>% collect_metrics()

pred_obs_xgb <- xgb_rs %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb$bias_rel)

sqrt(mean(pred_obs_xgb$bias_rel_square))

xgb_rs %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 



```

modèle Mars

```{r}
# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds <- vfold_cv(auc_train_train)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res <- tune_grid(
 mars_wf,
 resamples = env_folds,
 grid = mars_grid)


regular_res

#visualisation
regular_res %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars <- select_best(regular_res, "rmse", maximize=F)

final_mars <- finalize_model(
  mars_spec,
  best_rmse_mars
)

final_mars

final_mars %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars <- workflow() %>%
  add_recipe(auc_rec) %>%
  add_model(final_mars)

###resample#####
set.seed(456)
folds <- vfold_cv(auc_train_train)#par défaut 10 fois
set.seed(123)
mars_rs <- fit_resamples(object = final_wf_mars, resamples = folds, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs %>% collect_metrics()

#perfs
pred_obs_mars <- mars_rs %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars$bias_rel)

sqrt(mean(pred_obs_mars$bias_rel_square))

mars_rs %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


```
on va essayer de selectionner que 2 points ( avant 4 h pour le deuxième et pas a cote)
donc combinaison possible 
0/2
0/3
0/4
1/3
1/4

on commence par 0/2

```{r}

auc_0_2 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_0,out_2,auc)


set.seed(123)

splits <- initial_split(auc_0_2, strata = auc)
auc_train_0_2  <- training(splits)
auc_test_0_2   <- testing(splits)

set.seed(234)
auc_set_0_2  <- validation_split(auc_train_0_2, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_0_2<- analysis(auc_set_0_2$splits[[1]])
auc_train_test_0_2<-assessment(auc_set_0_2$splits[[1]])

auc_rec_0_2 <- recipe(auc ~ ., data = auc_train_train_0_2) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_0_2 <-  prep(auc_rec_0_2)
auc_train_recipe_0_2 <-juice(auc_prep_recipe_0_2)
summary(auc_train_recipe_0_2)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_0_2 <- vfold_cv(auc_train_train_0_2, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_0_2 <- tune_grid(
  glmnet_wf_0_2,
  resamples = auc_folds_0_2,
  grid = 30)


tune_glmnet_0_2%>% collect_metrics()

best_rmse_glmnet_0_2 <- select_best(tune_glmnet_0_2, "rmse",  maximize = F)
final_glmnet_0_2 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_0_2
)

final_glmnet_0_2


library(vip)

#finalize workflow
final_wf_glmnet_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(final_glmnet_0_2)

###resample#####
set.seed(456)
folds_0_2 <- vfold_cv(auc_train_train_0_2)#par défaut 10 fois
set.seed(123)
glmnet_rs_0_2 <- fit_resamples(object = final_wf_glmnet_0_2, resamples = folds_0_2, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_0_2 %>% collect_metrics()

pred_obs_glmnet_0_2 <- glmnet_rs_0_2 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_0_2$bias_rel)
sqrt(mean(pred_obs_glmnet_0_2$bias_rel_square))

glmnet_rs_0_2 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_0_2 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_0_2 <- vfold_cv(auc_train_train_0_2)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_0_2,
  resamples = auc_folds_0_2,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_0_2 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_0_2<- finalize_model(
  xgb_spec,
  best_rmse_xgb_0_2
)

final_xgb_0_2

final_xgb_0_2 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_2)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(final_xgb_0_2)%>%
  fit(auc_train_train_0_2)

###resample#####
set.seed(456)
folds_0_2 <- vfold_cv(auc_train_train_0_2)#par défaut 10 fois
set.seed(123)
xgb_rs_0_2 <- fit_resamples(object = final_wf_xgb_0_2, resamples = folds_0_2, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_0_2 %>% collect_metrics()

pred_obs_xgb_0_2 <- xgb_rs_0_2 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_0_2$bias_rel)

sqrt(mean(pred_obs_xgb_0_2$bias_rel_square))

xgb_rs_0_2 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_0_2 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_0_2 <- vfold_cv(auc_train_train_0_2)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_0_2 <- tune_grid(
 mars_wf_0_2,
 resamples = env_folds_0_2,
 grid = mars_grid)


regular_res

#visualisation
regular_res_0_2 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_0_2 <- select_best(regular_res_0_2, "rmse", maximize=F)

final_mars_0_2 <- finalize_model(
  mars_spec,
  best_rmse_mars_0_2
)

final_mars_0_2

final_mars_0_2 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_2)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_0_2 <- workflow() %>%
  add_recipe(auc_rec_0_2) %>%
  add_model(final_mars_0_2)

###resample#####
set.seed(456)
folds_0_2 <- vfold_cv(auc_train_train_0_2)#par défaut 10 fois
set.seed(123)
mars_rs_0_2 <- fit_resamples(object = final_wf_mars_0_2, resamples = folds_0_2, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_0_2 %>% collect_metrics()

#perfs
pred_obs_mars_0_2 <- mars_rs_0_2 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_0_2$bias_rel)

sqrt(mean(pred_obs_mars_0_2$bias_rel_square))

mars_rs_0_2 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_0_2 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


```

on fait 0/3

```{r}
auc_0_3 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_0,out_3,auc)


set.seed(123)

splits <- initial_split(auc_0_3, strata = auc)
auc_train_0_3  <- training(splits)
auc_test_0_3   <- testing(splits)

set.seed(234)
auc_set_0_3  <- validation_split(auc_train_0_3, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_0_3<- analysis(auc_set_0_3$splits[[1]])
auc_train_test_0_3<-assessment(auc_set_0_3$splits[[1]])

auc_rec_0_3 <- recipe(auc ~ ., data = auc_train_train_0_3) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_0_3 <-  prep(auc_rec_0_3)
auc_train_recipe_0_3 <-juice(auc_prep_recipe_0_3)
summary(auc_train_recipe_0_3)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_0_3 <- vfold_cv(auc_train_train_0_3, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_0_3 <- tune_grid(
  glmnet_wf_0_3,
  resamples = auc_folds_0_3,
  grid = 30)


tune_glmnet_0_3%>% collect_metrics()

best_rmse_glmnet_0_3 <- select_best(tune_glmnet_0_3, "rmse",  maximize = F)
final_glmnet_0_3<- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_0_3
)

final_glmnet_0_3


library(vip)

#finalize workflow
final_wf_glmnet_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(final_glmnet_0_3)

###resample#####
set.seed(456)
folds_0_3 <- vfold_cv(auc_train_train_0_3)#par défaut 10 fois
set.seed(123)
glmnet_rs_0_3 <- fit_resamples(object = final_wf_glmnet_0_3, resamples = folds_0_3, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_0_3 %>% collect_metrics()

pred_obs_glmnet_0_3 <- glmnet_rs_0_3 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_0_3$bias_rel)
sqrt(mean(pred_obs_glmnet_0_3$bias_rel_square))

glmnet_rs_0_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_0_3 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_0_3 <- vfold_cv(auc_train_train_0_3)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_0_3,
  resamples = auc_folds_0_3,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_0_3 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_0_3<- finalize_model(
  xgb_spec,
  best_rmse_xgb_0_3
)

final_xgb_0_3

final_xgb_0_3 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_3)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(final_xgb_0_3)%>%
  fit(auc_train_train_0_3)

###resample#####
set.seed(456)
folds_0_3 <- vfold_cv(auc_train_train_0_3)#par défaut 10 fois
set.seed(123)
xgb_rs_0_3 <- fit_resamples(object = final_wf_xgb_0_3, resamples = folds_0_3, control = control_resamples(verbose=T, save_pred = T))

 ##perf resample
xgb_rs_0_3 %>% collect_metrics()

pred_obs_xgb_0_3 <- xgb_rs_0_3 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_0_3$bias_rel)

sqrt(mean(pred_obs_xgb_0_3$bias_rel_square))

xgb_rs_0_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_0_3 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


  #### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_0_3 <- vfold_cv(auc_train_train_0_3)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_0_3 <- tune_grid(
 mars_wf_0_3,
 resamples = env_folds_0_3,
 grid = mars_grid)


regular_res

#visualisation
regular_res_0_3 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_0_3 <- select_best(regular_res_0_3, "rmse", maximize=F)

final_mars_0_3 <- finalize_model(
  mars_spec,
  best_rmse_mars_0_3
)

final_mars_0_3

final_mars_0_3 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_3)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_0_3 <- workflow() %>%
  add_recipe(auc_rec_0_3) %>%
  add_model(final_mars_0_3)

###resample#####
set.seed(456)
folds_0_3<- vfold_cv(auc_train_train_0_3)#par défaut 10 fois
set.seed(123)
mars_rs_0_3 <- fit_resamples(object = final_wf_mars_0_3, resamples = folds_0_3, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_0_3 %>% collect_metrics()

#perfs
pred_obs_mars_0_3 <- mars_rs_0_3 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_0_3$bias_rel)

sqrt(mean(pred_obs_mars_0_3$bias_rel_square))

mars_rs_0_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_0_3 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```

on fait le 0/4

```{r}
auc_0_4 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_0,out_4,auc)


set.seed(123)

splits <- initial_split(auc_0_4, strata = auc)
auc_train_0_4  <- training(splits)
auc_test_0_4   <- testing(splits)

set.seed(234)
auc_set_0_4  <- validation_split(auc_train_0_4, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_0_4<- analysis(auc_set_0_4$splits[[1]])
auc_train_test_0_4<-assessment(auc_set_0_4$splits[[1]])

auc_rec_0_4 <- recipe(auc ~ ., data = auc_train_train_0_4) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_0_4 <-  prep(auc_rec_0_4)
auc_train_recipe_0_4 <-juice(auc_prep_recipe_0_4)
summary(auc_train_recipe_0_4)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_0_4 <- vfold_cv(auc_train_train_0_4, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_0_4 <- tune_grid(
  glmnet_wf_0_4,
  resamples = auc_folds_0_4,
  grid = 30)


tune_glmnet_0_4%>% collect_metrics()

best_rmse_glmnet_0_4 <- select_best(tune_glmnet_0_2, "rmse",  maximize = F)
final_glmnet_0_4 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_0_4
)

final_glmnet_0_4


library(vip)

#finalize workflow
final_wf_glmnet_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(final_glmnet_0_4)

###resample#####
set.seed(456)
folds_0_4 <- vfold_cv(auc_train_train_0_4)#par défaut 10 fois
set.seed(123)
glmnet_rs_0_4 <- fit_resamples(object = final_wf_glmnet_0_4, resamples = folds_0_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_0_4 %>% collect_metrics()

pred_obs_glmnet_0_4 <- glmnet_rs_0_4 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_0_4$bias_rel)
sqrt(mean(pred_obs_glmnet_0_4$bias_rel_square))

glmnet_rs_0_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_0_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_0_4 <- vfold_cv(auc_train_train_0_4)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_0_4,
  resamples = auc_folds_0_4,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_0_4 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_0_4<- finalize_model(
  xgb_spec,
  best_rmse_xgb_0_4
)

final_xgb_0_4

final_xgb_0_4 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_4)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(final_xgb_0_4)%>%
  fit(auc_train_train_0_4)

###resample#####
set.seed(456)
folds_0_4 <- vfold_cv(auc_train_train_0_4)#par défaut 10 fois
set.seed(123)
xgb_rs_0_4 <- fit_resamples(object = final_wf_xgb_0_4, resamples = folds_0_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_0_4 %>% collect_metrics()

pred_obs_xgb_0_4 <- xgb_rs_0_4%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_0_4$bias_rel)

sqrt(mean(pred_obs_xgb_0_4$bias_rel_square))

xgb_rs_0_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_0_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_0_4 <- vfold_cv(auc_train_train_0_4)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_0_4 <- tune_grid(
 mars_wf_0_4,
 resamples = env_folds_0_4,
 grid = mars_grid)


regular_res_0_4

#visualisation
regular_res_0_4 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_0_4 <- select_best(regular_res_0_4, "rmse", maximize=F)

final_mars_0_4 <- finalize_model(
  mars_spec,
  best_rmse_mars_0_4
)

final_mars_0_4

final_mars_0_4 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_4)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_0_4 <- workflow() %>%
  add_recipe(auc_rec_0_4) %>%
  add_model(final_mars_0_4)

###resample#####
set.seed(456)
folds_0_4 <- vfold_cv(auc_train_train_0_4)#par défaut 10 fois
set.seed(123)
mars_rs_0_4 <- fit_resamples(object = final_wf_mars_0_4, resamples = folds_0_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_0_4 %>% collect_metrics()

#perfs
pred_obs_mars_0_4 <- mars_rs_0_4 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_0_4$bias_rel)

sqrt(mean(pred_obs_mars_0_4$bias_rel_square))

mars_rs_0_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_0_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```
on fait 1/3

```{r}
auc_1_3 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_1,out_3,auc)


set.seed(123)

splits <- initial_split(auc_1_3, strata = auc)
auc_train_1_3  <- training(splits)
auc_test_1_3   <- testing(splits)

set.seed(234)
auc_set_1_3  <- validation_split(auc_train_1_3, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_1_3<- analysis(auc_set_1_3$splits[[1]])
auc_train_test_1_3<-assessment(auc_set_1_3$splits[[1]])

auc_rec_1_3 <- recipe(auc ~ ., data = auc_train_train_1_3) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_1_3 <-  prep(auc_rec_1_3)
auc_train_recipe_1_3 <-juice(auc_prep_recipe_1_3)
summary(auc_train_recipe_1_3)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_1_3 <- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_1_3 <- vfold_cv(auc_train_train_1_3, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_1_3 <- tune_grid(
  glmnet_wf_1_3,
  resamples = auc_folds_1_3,
  grid = 30)


tune_glmnet_1_3%>% collect_metrics()

best_rmse_glmnet_1_3 <- select_best(tune_glmnet_1_3, "rmse",  maximize = F)
final_glmnet_1_3 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_1_3
)

final_glmnet_1_3


library(vip)

#finalize workflow
final_wf_glmnet_1_3<- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(final_glmnet_1_3)

###resample#####
set.seed(456)
folds_1_3 <- vfold_cv(auc_train_train_1_3)#par défaut 10 fois
set.seed(123)
glmnet_rs_1_3 <- fit_resamples(object = final_wf_glmnet_1_3, resamples = folds_1_3, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_1_3 %>% collect_metrics()

pred_obs_glmnet_1_3 <- glmnet_rs_1_3 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_1_3$bias_rel)
sqrt(mean(pred_obs_glmnet_1_3$bias_rel_square))

glmnet_rs_1_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_1_3%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_1_3<- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_1_3 <- vfold_cv(auc_train_train_1_3)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_1_3,
  resamples = auc_folds_1_3,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_1_3 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_1_3<- finalize_model(
  xgb_spec,
  best_rmse_xgb_1_3
)

final_xgb_1_3

final_xgb_1_3 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_3)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_1_3 <- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(final_xgb_1_3)%>%
  fit(auc_train_train_1_3)

###resample#####
set.seed(456)
folds_1_3 <- vfold_cv(auc_train_train_1_3)#par défaut 10 fois
set.seed(123)
xgb_rs_1_3 <- fit_resamples(object = final_wf_xgb_1_3, resamples = folds_1_3, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_1_3 %>% collect_metrics()

pred_obs_xgb_1_3 <- xgb_rs_1_3%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_1_3$bias_rel)

sqrt(mean(pred_obs_xgb_1_3$bias_rel_square))

xgb_rs_1_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_1_3 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_1_3 <- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_1_3 <- vfold_cv(auc_train_train_1_3)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_1_3 <- tune_grid(
 mars_wf_1_3,
 resamples = env_folds_1_3,
 grid = mars_grid)


regular_res_1_3

#visualisation
regular_res_1_3 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_1_3 <- select_best(regular_res_1_3, "rmse", maximize=F)

final_mars_1_3 <- finalize_model(
  mars_spec,
  best_rmse_mars_1_3
)

final_mars_1_3

final_mars_1_3 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_3)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_1_3 <- workflow() %>%
  add_recipe(auc_rec_1_3) %>%
  add_model(final_mars_1_3)

###resample#####
set.seed(456)
folds_1_3 <- vfold_cv(auc_train_train_1_3)#par défaut 10 fois
set.seed(123)
mars_rs_1_3 <- fit_resamples(object = final_wf_mars_1_3, resamples = folds_1_3, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_1_3 %>% collect_metrics()

#perfs
pred_obs_mars_1_3<- mars_rs_1_3 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_1_3$bias_rel)

sqrt(mean(pred_obs_mars_1_3$bias_rel_square))

mars_rs_1_3 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_1_3 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```
on fait 2/4

```{r}
auc_2_4 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_2,out_4,auc)


set.seed(123)

splits <- initial_split(auc_2_4, strata = auc)
auc_train_2_4  <- training(splits)
auc_test_2_4   <- testing(splits)

set.seed(234)
auc_set_2_4  <- validation_split(auc_train_2_4, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_2_4<- analysis(auc_set_2_4$splits[[1]])
auc_train_test_2_4<-assessment(auc_set_2_4$splits[[1]])

auc_rec_2_4 <- recipe(auc ~ ., data = auc_train_train_2_4) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_2_4 <-  prep(auc_rec_2_4)
auc_train_recipe_2_4 <-juice(auc_prep_recipe_2_4)
summary(auc_train_recipe_2_4)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_2_4 <- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_2_4 <- vfold_cv(auc_train_train_2_4, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_2_4 <- tune_grid(
  glmnet_wf_2_4,
  resamples = auc_folds_2_4,
  grid = 30)


tune_glmnet_2_4%>% collect_metrics()

best_rmse_glmnet_2_4 <- select_best(tune_glmnet_2_4, "rmse",  maximize = F)
final_glmnet_2_4 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_2_4
)

final_glmnet_2_4


library(vip)

#finalize workflow
final_wf_glmnet_2_4<- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(final_glmnet_2_4)

###resample#####
set.seed(456)
folds_2_4 <- vfold_cv(auc_train_train_2_4)#par défaut 10 fois
set.seed(123)
glmnet_rs_2_4 <- fit_resamples(object = final_wf_glmnet_2_4, resamples = folds_2_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_2_4 %>% collect_metrics()

pred_obs_glmnet_2_4 <- glmnet_rs_2_4 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_2_4$bias_rel)
sqrt(mean(pred_obs_glmnet_2_4$bias_rel_square))

glmnet_rs_2_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_2_4%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_2_4<- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_2_4 <- vfold_cv(auc_train_train_2_4)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_2_4,
  resamples = auc_folds_2_4,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_2_4 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_2_4<- finalize_model(
  xgb_spec,
  best_rmse_xgb_2_4
)

final_xgb_2_4

final_xgb_2_4 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_2_4)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_2_4 <- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(final_xgb_2_4)%>%
  fit(auc_train_train_2_4)

###resample#####
set.seed(456)
folds_2_4 <- vfold_cv(auc_train_train_2_4)#par défaut 10 fois
set.seed(123)
xgb_rs_2_4 <- fit_resamples(object = final_wf_xgb_2_4, resamples = folds_2_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_2_4 %>% collect_metrics()

pred_obs_xgb_2_4 <- xgb_rs_2_4%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_2_4$bias_rel)

sqrt(mean(pred_obs_xgb_2_4$bias_rel_square))

xgb_rs_2_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_2_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_2_4 <- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_2_4 <- vfold_cv(auc_train_train_2_4)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_2_4 <- tune_grid(
 mars_wf_2_4,
 resamples = env_folds_2_4,
 grid = mars_grid)


regular_res_2_4

#visualisation
regular_res_2_4 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_2_4 <- select_best(regular_res_2_4, "rmse", maximize=F)

final_mars_2_4 <- finalize_model(
  mars_spec,
  best_rmse_mars_2_4
)

final_mars_2_4

final_mars_2_4 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_2_4)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_2_4 <- workflow() %>%
  add_recipe(auc_rec_2_4) %>%
  add_model(final_mars_2_4)

###resample#####
set.seed(456)
folds_2_4 <- vfold_cv(auc_train_train_2_4)#par défaut 10 fois
set.seed(123)
mars_rs_2_4 <- fit_resamples(object = final_wf_mars_2_4, resamples = folds_2_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_2_4 %>% collect_metrics()

#perfs
pred_obs_mars_2_4<- mars_rs_2_4%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_2_4$bias_rel)

sqrt(mean(pred_obs_mars_2_4$bias_rel_square))

mars_rs_2_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_2_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```

on fait le 1/4

```{r}
auc_1_4 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_1,out_4,auc)


set.seed(123)

splits <- initial_split(auc_1_4, strata = auc)
auc_train_1_4  <- training(splits)
auc_test_1_4   <- testing(splits)

set.seed(234)
auc_set_1_4  <- validation_split(auc_train_1_4, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_1_4<- analysis(auc_set_1_4$splits[[1]])
auc_train_test_1_4<-assessment(auc_set_1_4$splits[[1]])

auc_rec_1_4 <- recipe(auc ~ ., data = auc_train_train_1_4) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_1_4 <-  prep(auc_rec_1_4)
auc_train_recipe_1_4 <-juice(auc_prep_recipe_1_4)
summary(auc_train_recipe_1_4)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_1_4 <- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_1_4 <- vfold_cv(auc_train_train_1_4, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_1_4 <- tune_grid(
  glmnet_wf_1_4,
  resamples = auc_folds_1_4,
  grid = 30)


tune_glmnet_1_4%>% collect_metrics()

best_rmse_glmnet_1_4 <- select_best(tune_glmnet_1_4, "rmse",  maximize = F)
final_glmnet_1_4 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_1_4
)

final_glmnet_1_4


library(vip)

#finalize workflow
final_wf_glmnet_1_4<- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(final_glmnet_1_4)

###resample#####
set.seed(456)
folds_1_4 <- vfold_cv(auc_train_train_1_4)#par défaut 10 fois
set.seed(123)
glmnet_rs_1_4 <- fit_resamples(object = final_wf_glmnet_1_4, resamples = folds_1_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_1_4 %>% collect_metrics()

pred_obs_glmnet_1_4 <- glmnet_rs_1_4 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_1_4$bias_rel)
sqrt(mean(pred_obs_glmnet_1_4$bias_rel_square))

glmnet_rs_1_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_1_4%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_1_4<- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_1_4 <- vfold_cv(auc_train_train_1_4)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_1_4,
  resamples = auc_folds_1_4,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_1_4 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_1_4<- finalize_model(
  xgb_spec,
  best_rmse_xgb_1_4
)

final_xgb_1_4

final_xgb_1_4 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_4)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_1_4 <- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(final_xgb_1_4)%>%
  fit(auc_train_train_1_4)

###resample#####
set.seed(456)
folds_1_4 <- vfold_cv(auc_train_train_1_4)#par défaut 10 fois
set.seed(123)
xgb_rs_1_4 <- fit_resamples(object = final_wf_xgb_1_4, resamples = folds_1_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_1_4 %>% collect_metrics()

pred_obs_xgb_1_4 <- xgb_rs_1_4%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_1_4$bias_rel)

sqrt(mean(pred_obs_xgb_1_4$bias_rel_square))

xgb_rs_1_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_1_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_1_4 <- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_1_4 <- vfold_cv(auc_train_train_1_4)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_1_4 <- tune_grid(
 mars_wf_1_4,
 resamples = env_folds_1_4,
 grid = mars_grid)


regular_res_1_4

#visualisation
regular_res_1_4 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_1_4 <- select_best(regular_res_1_4, "rmse", maximize=F)

final_mars_1_4 <- finalize_model(
  mars_spec,
  best_rmse_mars_1_4
)

final_mars_1_4

final_mars_1_4 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_4)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_1_4 <- workflow() %>%
  add_recipe(auc_rec_1_4) %>%
  add_model(final_mars_1_4)

###resample#####
set.seed(456)
folds_1_4 <- vfold_cv(auc_train_train_1_4)#par défaut 10 fois
set.seed(123)
mars_rs_1_4 <- fit_resamples(object = final_wf_mars_1_4, resamples = folds_1_4, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_1_4 %>% collect_metrics()

#perfs
pred_obs_mars_1_4<- mars_rs_1_4%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_1_4$bias_rel)

sqrt(mean(pred_obs_mars_1_4$bias_rel_square))

mars_rs_1_4 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_1_4 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```

on developpe sur autres points 0/6

```{r}
auc_0_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_0,out_6,auc)


set.seed(123)

splits <- initial_split(auc_0_6, strata = auc)
auc_train_0_6  <- training(splits)
auc_test_0_6   <- testing(splits)

set.seed(234)
auc_set_0_6  <- validation_split(auc_train_0_6, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_0_6<- analysis(auc_set_0_6$splits[[1]])
auc_train_test_0_6<-assessment(auc_set_0_6$splits[[1]])

auc_rec_0_6 <- recipe(auc ~ ., data = auc_train_train_0_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_0_6 <-  prep(auc_rec_0_6)
auc_train_recipe_0_6 <-juice(auc_prep_recipe_0_6)
summary(auc_train_recipe_0_6)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_0_6 <- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_0_6 <- vfold_cv(auc_train_train_0_6, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_0_6 <- tune_grid(
  glmnet_wf_0_6,
  resamples = auc_folds_0_6,
  grid = 30)


tune_glmnet_0_6%>% collect_metrics()

best_rmse_glmnet_0_6 <- select_best(tune_glmnet_0_6, "rmse",  maximize = F)
final_glmnet_0_6 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_0_6
)

final_glmnet_0_6


library(vip)

#finalize workflow
final_wf_glmnet_0_6<- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(final_glmnet_0_6)

###resample#####
set.seed(456)
folds_0_6 <- vfold_cv(auc_train_train_0_6)#par défaut 10 fois
set.seed(123)
glmnet_rs_0_6 <- fit_resamples(object = final_wf_glmnet_0_6, resamples = folds_0_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_0_6 %>% collect_metrics()

pred_obs_glmnet_0_6 <- glmnet_rs_0_6 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_0_6$bias_rel)
sqrt(mean(pred_obs_glmnet_0_6$bias_rel_square))

glmnet_rs_0_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_0_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_0_6<- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_0_6<- vfold_cv(auc_train_train_0_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_0_6,
  resamples = auc_folds_0_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_0_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_0_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_0_6
)

final_xgb_0_6

final_xgb_0_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_6)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_0_6 <- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(final_xgb_0_6)%>%
  fit(auc_train_train_0_6)

###resample#####
set.seed(456)
folds_0_6 <- vfold_cv(auc_train_train_0_6)#par défaut 10 fois
set.seed(123)
xgb_rs_0_6 <- fit_resamples(object = final_wf_xgb_0_6, resamples = folds_0_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_0_6 %>% collect_metrics()

pred_obs_xgb_0_6 <- xgb_rs_0_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_1_4$bias_rel)

sqrt(mean(pred_obs_xgb_1_4$bias_rel_square))

xgb_rs_0_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_0_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_0_6 <- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_0_6<- vfold_cv(auc_train_train_0_6)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_0_6 <- tune_grid(
 mars_wf_0_6,
 resamples = env_folds_0_6,
 grid = mars_grid)


regular_res_0_6

#visualisation
regular_res_0_6 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_0_6 <- select_best(regular_res_0_6, "rmse", maximize=F)

final_mars_0_6 <- finalize_model(
  mars_spec,
  best_rmse_mars_0_6
)

final_mars_0_6

final_mars_0_6 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_0_6)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_0_6 <- workflow() %>%
  add_recipe(auc_rec_0_6) %>%
  add_model(final_mars_0_6)

###resample#####
set.seed(456)
folds_0_6 <- vfold_cv(auc_train_train_0_6)#par défaut 10 fois
set.seed(123)
mars_rs_0_6 <- fit_resamples(object = final_wf_mars_0_6, resamples = folds_0_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_0_6 %>% collect_metrics()

#perfs
pred_obs_mars_0_6<- mars_rs_0_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_0_6$bias_rel)

sqrt(mean(pred_obs_mars_0_6$bias_rel_square))

mars_rs_0_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_0_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```

point 1/6

```{r}
auc_1_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_1,out_6,auc)


set.seed(123)

splits <- initial_split(auc_1_6, strata = auc)
auc_train_1_6  <- training(splits)
auc_test_1_6   <- testing(splits)

set.seed(234)
auc_set_1_6  <- validation_split(auc_train_1_6, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_1_6<- analysis(auc_set_1_6$splits[[1]])
auc_train_test_1_6<-assessment(auc_set_1_6$splits[[1]])

auc_rec_1_6 <- recipe(auc ~ ., data = auc_train_train_1_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_1_6 <-  prep(auc_rec_1_6)
auc_train_recipe_1_6 <-juice(auc_prep_recipe_1_6)
summary(auc_train_recipe_1_6)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_1_6 <- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_1_6 <- vfold_cv(auc_train_train_1_6, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_1_6 <- tune_grid(
  glmnet_wf_1_6,
  resamples = auc_folds_1_6,
  grid = 30)


tune_glmnet_1_6%>% collect_metrics()

best_rmse_glmnet_1_6 <- select_best(tune_glmnet_1_6, "rmse",  maximize = F)
final_glmnet_1_6 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_1_6
)

final_glmnet_1_6


library(vip)

#finalize workflow
final_wf_glmnet_1_6<- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(final_glmnet_1_6)

###resample#####
set.seed(456)
folds_1_6 <- vfold_cv(auc_train_train_1_6)#par défaut 10 fois
set.seed(123)
glmnet_rs_1_6 <- fit_resamples(object = final_wf_glmnet_1_6, resamples = folds_1_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_1_6 %>% collect_metrics()

pred_obs_glmnet_1_6 <- glmnet_rs_1_6 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_1_6$bias_rel)
sqrt(mean(pred_obs_glmnet_1_6$bias_rel_square))

glmnet_rs_1_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_1_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_1_6<- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_1_6<- vfold_cv(auc_train_train_1_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_1_6,
  resamples = auc_folds_1_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_1_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_1_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_1_6
)

final_xgb_1_6

final_xgb_1_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_6)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_1_6 <- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(final_xgb_1_6)%>%
  fit(auc_train_train_1_6)

###resample#####
set.seed(456)
folds_1_6 <- vfold_cv(auc_train_train_1_6)#par défaut 10 fois
set.seed(123)
xgb_rs_1_6 <- fit_resamples(object = final_wf_xgb_1_6, resamples = folds_1_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_1_6 %>% collect_metrics()

pred_obs_xgb_1_6 <- xgb_rs_1_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_1_6$bias_rel)

sqrt(mean(pred_obs_xgb_1_6$bias_rel_square))

xgb_rs_1_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_1_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_1_6 <- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_1_6<- vfold_cv(auc_train_train_1_6)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_1_6 <- tune_grid(
 mars_wf_1_6,
 resamples = env_folds_1_6,
 grid = mars_grid)


regular_res_1_6

#visualisation
regular_res_1_6 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_1_6 <- select_best(regular_res_1_6, "rmse", maximize=F)

final_mars_1_6 <- finalize_model(
  mars_spec,
  best_rmse_mars_1_6
)

final_mars_1_6

final_mars_1_6 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_1_6)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_1_6 <- workflow() %>%
  add_recipe(auc_rec_1_6) %>%
  add_model(final_mars_1_6)

###resample#####
set.seed(456)
folds_1_6 <- vfold_cv(auc_train_train_1_6)#par défaut 10 fois
set.seed(123)
mars_rs_1_6 <- fit_resamples(object = final_wf_mars_1_6, resamples = folds_1_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_1_6 %>% collect_metrics()

#perfs
pred_obs_mars_1_6<- mars_rs_1_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_1_6$bias_rel)

sqrt(mean(pred_obs_mars_1_6$bias_rel_square))

mars_rs_1_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_1_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```


point 2/6

```{r}
auc_2_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_2,out_6,auc)


set.seed(123)

splits <- initial_split(auc_2_6, strata = auc)
auc_train_2_6  <- training(splits)
auc_test_2_6   <- testing(splits)

set.seed(234)
auc_set_2_6  <- validation_split(auc_train_2_6, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_2_6<- analysis(auc_set_2_6$splits[[1]])
auc_train_test_2_6<-assessment(auc_set_2_6$splits[[1]])

auc_rec_2_6 <- recipe(auc ~ ., data = auc_train_train_2_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_2_6 <-  prep(auc_rec_2_6)
auc_train_recipe_2_6 <-juice(auc_prep_recipe_2_6)
summary(auc_train_recipe_2_6)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_2_6 <- vfold_cv(auc_train_train_2_6, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_2_6 <- tune_grid(
  glmnet_wf_2_6,
  resamples = auc_folds_2_6,
  grid = 30)


tune_glmnet_2_6%>% collect_metrics()

best_rmse_glmnet_2_6 <- select_best(tune_glmnet_2_6, "rmse",  maximize = F)
final_glmnet_2_6 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_2_6
)

final_glmnet_2_6


library(vip)

#finalize workflow
final_wf_glmnet_2_6<- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(final_glmnet_2_6)

###resample#####
set.seed(456)
folds_2_6 <- vfold_cv(auc_train_train_2_6)#par défaut 10 fois
set.seed(123)
glmnet_rs_2_6 <- fit_resamples(object = final_wf_glmnet_2_6, resamples = folds_2_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_2_6 %>% collect_metrics()

pred_obs_glmnet_2_6 <- glmnet_rs_2_6 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_2_6$bias_rel)
sqrt(mean(pred_obs_glmnet_2_6$bias_rel_square))

glmnet_rs_2_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_2_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_2_6<- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_2_6<- vfold_cv(auc_train_train_2_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_2_6,
  resamples = auc_folds_2_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_2_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_2_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_2_6
)

final_xgb_2_6

final_xgb_2_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_2_6)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(final_xgb_2_6)%>%
  fit(auc_train_train_2_6)

###resample#####
set.seed(456)
folds_2_6 <- vfold_cv(auc_train_train_2_6)#par défaut 10 fois
set.seed(123)
xgb_rs_2_6 <- fit_resamples(object = final_wf_xgb_2_6, resamples = folds_2_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_2_6 %>% collect_metrics()

pred_obs_xgb_2_6 <- xgb_rs_2_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_2_6$bias_rel)

sqrt(mean(pred_obs_xgb_2_6$bias_rel_square))

xgb_rs_2_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_2_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_2_6<- vfold_cv(auc_train_train_2_6)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_2_6 <- tune_grid(
 mars_wf_2_6,
 resamples = env_folds_2_6,
 grid = mars_grid)


regular_res_2_6

#visualisation
regular_res_2_6 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_2_6 <- select_best(regular_res_2_6, "rmse", maximize=F)

final_mars_2_6 <- finalize_model(
  mars_spec,
  best_rmse_mars_2_6
)

final_mars_2_6

final_mars_2_6 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_2_6)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(final_mars_2_6)

###resample#####
set.seed(456)
folds_2_6 <- vfold_cv(auc_train_train_2_6)#par défaut 10 fois
set.seed(123)
mars_rs_2_6 <- fit_resamples(object = final_wf_mars_2_6, resamples = folds_2_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_2_6 %>% collect_metrics()

#perfs
pred_obs_mars_2_6<- mars_rs_2_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_2_6$bias_rel)

sqrt(mean(pred_obs_mars_2_6$bias_rel_square))

mars_rs_2_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_2_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


mars_wf_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(mars_spec) %>% 
  fit(auc_train_test_2_6)

summary(auc_train_test_2_6)

predict_2_6=predict(mars_wf_2_6,auc_train_test_2_6)%>%
     bind_cols(auc=auc_train_test_2_6$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

rmarkdown::paged_table(as.data.frame(predict_2_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

```


point 3/6

```{r}
auc_3_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_3,out_6,auc)


set.seed(123)

splits <- initial_split(auc_3_6, strata = auc)
auc_train_3_6  <- training(splits)
auc_test_3_6   <- testing(splits)

set.seed(234)
auc_set_3_6  <- validation_split(auc_train_3_6, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_3_6<- analysis(auc_set_3_6$splits[[1]])
auc_train_test_3_6<-assessment(auc_set_3_6$splits[[1]])

auc_rec_3_6 <- recipe(auc ~ ., data = auc_train_train_3_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_3_6 <-  prep(auc_rec_3_6)
auc_train_recipe_3_6 <-juice(auc_prep_recipe_3_6)
summary(auc_train_recipe_3_6)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_3_6 <- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_3_6 <- vfold_cv(auc_train_train_3_6, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_3_6 <- tune_grid(
  glmnet_wf_3_6,
  resamples = auc_folds_3_6,
  grid = 30)


tune_glmnet_3_6%>% collect_metrics()

best_rmse_glmnet_3_6 <- select_best(tune_glmnet_3_6, "rmse",  maximize = F)
final_glmnet_3_6 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_3_6
)

final_glmnet_3_6


library(vip)

#finalize workflow
final_wf_glmnet_3_6<- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(final_glmnet_3_6)

###resample#####
set.seed(456)
folds_3_6 <- vfold_cv(auc_train_train_3_6)#par défaut 10 fois
set.seed(123)
glmnet_rs_3_6 <- fit_resamples(object = final_wf_glmnet_3_6, resamples = folds_3_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_3_6 %>% collect_metrics()

pred_obs_glmnet_3_6 <- glmnet_rs_3_6 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_3_6$bias_rel)
sqrt(mean(pred_obs_glmnet_3_6$bias_rel_square))

glmnet_rs_3_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_3_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))



# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_3_6<- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_3_6<- vfold_cv(auc_train_train_3_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_3_6,
  resamples = auc_folds_3_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_3_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_3_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_3_6
)

final_xgb_3_6

final_xgb_3_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_3_6)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_3_6 <- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(final_xgb_3_6)%>%
  fit(auc_train_train_3_6)

###resample#####
set.seed(456)
folds_3_6 <- vfold_cv(auc_train_train_3_6)#par défaut 10 fois
set.seed(123)
xgb_rs_3_6 <- fit_resamples(object = final_wf_xgb_3_6, resamples = folds_3_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_3_6 %>% collect_metrics()

pred_obs_xgb_3_6 <- xgb_rs_3_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_3_6$bias_rel)

sqrt(mean(pred_obs_xgb_3_6$bias_rel_square))

xgb_rs_3_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_3_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_3_6 <- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_3_6<- vfold_cv(auc_train_train_3_6)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_3_6 <- tune_grid(
 mars_wf_3_6,
 resamples = env_folds_3_6,
 grid = mars_grid)


regular_res_3_6

#visualisation
regular_res_3_6 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_3_6 <- select_best(regular_res_3_6, "rmse", maximize=F)

final_mars_3_6 <- finalize_model(
  mars_spec,
  best_rmse_mars_3_6
)

final_mars_3_6

final_mars_3_6 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_3_6)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_3_6 <- workflow() %>%
  add_recipe(auc_rec_3_6) %>%
  add_model(final_mars_3_6)

###resample#####
set.seed(456)
folds_3_6 <- vfold_cv(auc_train_train_3_6)#par défaut 10 fois
set.seed(123)
mars_rs_3_6 <- fit_resamples(object = final_wf_mars_3_6, resamples = folds_3_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_3_6 %>% collect_metrics()

#perfs
pred_obs_mars_3_6<- mars_rs_3_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_3_6$bias_rel)

sqrt(mean(pred_obs_mars_3_6$bias_rel_square))

mars_rs_3_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_3_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))
```

point 4/6
```{r}
auc_4_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_4,out_6,auc)


set.seed(123)

splits <- initial_split(auc_4_6, strata = auc)
auc_train_4_6  <- training(splits)
auc_test_4_6   <- testing(splits)

set.seed(234)
auc_set_4_6  <- validation_split(auc_train_4_6, 
                            strata = auc, 
                            prop = 0.80)

auc_train_train_4_6<- analysis(auc_set_4_6$splits[[1]])
auc_train_test_4_6<-assessment(auc_set_4_6$splits[[1]])

auc_rec_4_6 <- recipe(auc ~ ., data = auc_train_train_4_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_4_6 <-  prep(auc_rec_4_6)
auc_train_recipe_4_6 <-juice(auc_prep_recipe_4_6)
summary(auc_train_recipe_4_6)


### glmnet
glmnet_spec <- linear_reg(penalty=tune(),mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

#workflow model+recipe
glmnet_wf_4_6 <- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(glmnet_spec)


##hyperparameters
set.seed(2345)
auc_folds_4_6 <- vfold_cv(auc_train_train_4_6, v=10)#par défaut 10 fois

#tuning
set.seed(345)
tune_glmnet_4_6 <- tune_grid(
  glmnet_wf_4_6,
  resamples = auc_folds_4_6,
  grid = 30)


tune_glmnet_4_6%>% collect_metrics()

best_rmse_glmnet_4_6 <- select_best(tune_glmnet_4_6, "rmse",  maximize = F)
final_glmnet_4_6 <- finalize_model(
  glmnet_spec,
  best_rmse_glmnet_4_6
)

final_glmnet_4_6


library(vip)

#finalize workflow
final_wf_glmnet_4_6<- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_glmnet_4_6)

###resample#####
set.seed(456)
folds_4_6 <- vfold_cv(auc_train_train_4_6)#par défaut 10 fois
set.seed(123)
glmnet_rs_4_6 <- fit_resamples(object = final_wf_glmnet_4_6, resamples = folds_4_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
glmnet_rs_4_6 %>% collect_metrics()

pred_obs_glmnet_4_6 <- glmnet_rs_4_6 %>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_glmnet_4_6$bias_rel)
sqrt(mean(pred_obs_glmnet_4_6$bias_rel_square))

glmnet_rs_4_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_glmnet_4_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

final_wf_glmnet_4_6<- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_glmnet_4_6)%>%
  fit(auc_train_test_4_6)

predict_4_6=predict(final_wf_glmnet_4_6,auc_train_test_4_6)%>%
     bind_cols(auc=auc_train_test_4_6$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

rmarkdown::paged_table(as.data.frame(predict_4_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_4_6<- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_4_6<- vfold_cv(auc_train_train_4_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_4_6,
  resamples = auc_folds_4_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_4_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_4_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_4_6
)

final_xgb_4_6

final_xgb_4_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_4_6)
  ) %>%
  vip::vip(geom = "col")

#finalize workflow
final_wf_xgb_4_6 <- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_xgb_4_6)%>%
  fit(auc_train_train_4_6)

###resample#####
set.seed(456)
folds_4_6 <- vfold_cv(auc_train_train_4_6)#par défaut 10 fois
set.seed(123)
xgb_rs_4_6 <- fit_resamples(object = final_wf_xgb_4_6, resamples = folds_4_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_4_6 %>% collect_metrics()

pred_obs_xgb_4_6 <- xgb_rs_4_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_4_6$bias_rel)

sqrt(mean(pred_obs_xgb_4_6$bias_rel_square))

xgb_rs_4_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_4_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

final_wf_xgb_4_6<- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_xgb_4_6)%>%
  fit(auc_train_test_4_6)

predict_4_6=predict(final_wf_xgb_4_6,auc_train_test_4_6)%>%
     bind_cols(auc=auc_train_test_4_6$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

rmarkdown::paged_table(as.data.frame(predict_4_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


#### mars

# workflow mars

mars_spec <- mars(num_terms = tune(), prod_degree = tune()) %>%
  set_engine("earth") %>%
  set_mode("regression")

#workflow model+recipe
mars_wf_4_6 <- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(mars_spec)

set.seed(345)
#on reaffine grid
mars_grid <- grid_regular(
  num_terms(range = c(1L, 36L)),
  prod_degree(range = c(1L, 2L)),
  levels = 20
)

mars_grid



##hyperparameters
set.seed(2345)
env_folds_4_6<- vfold_cv(auc_train_train_4_6)#par défaut 10 fois


#retune
set.seed(456)
library(earth)
regular_res_4_6 <- tune_grid(
 mars_wf_4_6,
 resamples = env_folds_4_6,
 grid = mars_grid)


regular_res_4_6

#visualisation
regular_res_4_6 %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(prod_degree = factor(prod_degree)) %>%
  ggplot(aes(num_terms, mean, color = prod_degree)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "RMSE")

#visualisation des résultats
library(vip)
#choix du best model
best_rmse_mars_4_6 <- select_best(regular_res_4_6, "rmse", maximize=F)

final_mars_4_6 <- finalize_model(
  mars_spec,
  best_rmse_mars_4_6
)

final_mars_4_6

final_mars_4_6 %>%
  set_engine("earth") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_4_6)
  ) %>%
  vip(geom = "col")


#finalize workflow
final_wf_mars_4_6 <- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_mars_4_6)

###resample#####
set.seed(456)
folds_4_6 <- vfold_cv(auc_train_train_4_6)#par défaut 10 fois
set.seed(123)
mars_rs_4_6 <- fit_resamples(object = final_wf_mars_4_6, resamples = folds_4_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
mars_rs_4_6 %>% collect_metrics()

#perfs
pred_obs_mars_4_6<- mars_rs_4_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

mean(pred_obs_mars_4_6$bias_rel)

sqrt(mean(pred_obs_mars_4_6$bias_rel_square))

mars_rs_4_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 


rmarkdown::paged_table(as.data.frame(pred_obs_mars_4_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))


final_wf_mars_4_6<- workflow() %>%
  add_recipe(auc_rec_4_6) %>%
  add_model(final_mars_4_6)%>%
  fit(auc_train_test_4_6)

predict_4_6=predict(final_wf_mars_4_6,auc_train_test_4_6)%>%
     bind_cols(auc=auc_train_test_4_6$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

rmarkdown::paged_table(as.data.frame(predict_4_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))




```



xgboost sur les points 2/6 a les meilleurs performances. on redev sur la base train 


```{r}
library(tidyverse)
library(tidymodels)
auc_2_6 <- auc_1 %>% select(Pds,Clcreat,age,taille,SEX,SC_mosteller,greffe,amt,out_2,out_6,auc)


set.seed(123)

splits <- initial_split(auc_2_6, strata = auc)
auc_train_2_6  <- training(splits)
auc_test_2_6   <- testing(splits)


auc_rec_2_6 <- recipe(auc ~ ., data = auc_train_2_6) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(greffe,SEX,one_hot=T) 

auc_prep_recipe_2_6 <-  prep(auc_rec_2_6)
auc_train_recipe_2_6 <-juice(auc_prep_recipe_2_6)
summary(auc_train_recipe_2_6)




# xgboost

 #model
xgb_spec <- boost_tree(mode = "regression",
                        mtry = tune(),
                        trees = 1000,
                        min_n = tune(),
                        tree_depth = tune(),
                        sample_size=tune(),
                        learn_rate = tune()) %>% set_engine("xgboost")

#workflow model+recipe
xgb_wf_2_6<- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(xgb_spec)
#
##hyperparameters
set.seed(2345)
auc_folds_2_6 <- vfold_cv(auc_train_2_6)#par défaut 10 fois

#tuning
set.seed(345)
tune_xgb <- tune_grid(
  xgb_wf_2_6,
  resamples = auc_folds_2_6,
  grid = 30)


#visualisatin resultats
tune_xgb %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  dplyr::select(mean, min_n, mtry, learn_rate, tree_depth,sample_size) %>%
  pivot_longer(min_n:tree_depth,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "RMSE")

#choix du best model
best_rmse_xgb_2_6 <- select_best(tune_xgb, "rmse",  maximize = F)

final_xgb_2_6<- finalize_model(
  xgb_spec,
  best_rmse_xgb_2_6
)

final_xgb_2_6

final_xgb_2_6 %>%
  set_engine("xgboost", importance = "permutation") %>%
  fit(auc ~ .,
      data = juice(auc_prep_recipe_2_6)
  ) %>%
  vip::vip(geom = "col")
library(tidymodels)
#finalize workflow
final_wf_xgb_2_6 <- workflow() %>%
  add_recipe(auc_rec_2_6) %>%
  add_model(final_xgb_2_6)%>%
  fit(auc_train_2_6)

###resample#####
set.seed(456)
folds_2_6 <- vfold_cv(auc_train_2_6)#par défaut 10 fois
set.seed(123)
xgb_rs_2_6 <- fit_resamples(object = final_wf_xgb_2_6, resamples = folds_2_6, control = control_resamples(verbose=T, save_pred = T))

##perf resample
xgb_rs_2_6 %>% collect_metrics()

pred_obs_xgb_2_6 <- xgb_rs_2_6%>% collect_predictions() %>%
   mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)


#perfs
mean(pred_obs_xgb_2_6$bias_rel)

sqrt(mean(pred_obs_xgb_2_6$bias_rel_square))

xgb_rs_2_6 %>%
  collect_predictions() %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

rmarkdown::paged_table(as.data.frame(pred_obs_xgb_2_6%>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

#saveRDS(final_wf_xgb_2_6, "final_wf_xgb_2_6_PO.rds")

```




on prédit sur la base test 


```{r}
library(tidyverse)
predict_xgb_2_6=predict(final_wf_xgb_2_6,auc_test_2_6)%>%
     bind_cols(auc=auc_test_2_6$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)

rmarkdown::paged_table(as.data.frame(predict_xgb_2_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

predict_xgb_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

predict_xgb_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc-.pred)) + 
  geom_point() +
  geom_smooth(method=lm)


pm <-predict_xgb_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) +labs(
    x = "Predicted AUC ",
    y = "Reference AUC ")+  theme_bw()


library(knitr)
library(blandr)

statistics.results <- blandr.statistics(predict_xgb_2_6$auc , predict_xgb_2_6$.pred )

bg <-blandr.plot.ggplot( statistics.results , plotTitle = "" , ciDisplay = F, ciShading = FALSE)+theme_bw()

library(gridExtra)

grid.arrange(pm,bg,ncol=2, nrow=1)




```
on regarde sur base externe


```{r}
base_externe1 <- read_csv("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/Val_po_20191210.csv", na = c("", "NA", "D", "K", "A", "NF"),locale = locale("fr")) 

base_externe1 <- base_externe1 %>% select( TIME,OUT,CREAT,DOSE,EVID,POIDS,ID)%>% rename (Pds=POIDS)%>% mutate(CREAT=lead(CREAT))#%>% filter (EVID=="1")

#base_externe2 <- read_csv("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/gcvch.csv", na = c("", "NA", "D", "K", "A", "NF"),locale = locale("fr")) 

#base_externe2 <- base_externe2 %>% select(WT,HGT,BSA,DOSE,EVID,ID,SCHWADJ,AGE)%>% rename (Pds=WT, Clcreat= SCHWADJ,taille=HGT,age=AGE )%>% dplyr::filter (EVID=="1") %>% select (Pds, Clcreat,taille,ID,DOSE,EVID) %>% mutate(SC_mosteller= sqrt((taille*Pds)/3600))

base_externe2<- read_csv("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/val_potouspts_AA_20191217.csv", na = c("", "NA", "D", "K", "A", "NF"),locale = locale("fr"))%>% select(TIME,OUT,WT,HGT,BSA,DOSE,EVID,ID,SCHWADJ,AGE,SEX)%>% rename (Pds=WT, Clcreat= SCHWADJ,taille=HGT,age=AGE ) %>% filter (EVID=="1") %>% select (OUT,TIME,Pds, Clcreat,taille,ID,DOSE,age,SEX) %>% mutate(SC_mosteller= sqrt((taille*Pds)/3600)) %>% mutate(lieu="norway")%>% mutate(SEX2=case_when(SEX=="1"~"garcon",SEX=="0"~"fille")) %>% select(-SEX)%>% rename(SEX=SEX2)%>% mutate(greffe="moelle")%>% mutate(INTERDOSE=24)


base_externe3 <- read_csv("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/val_touspoints_po.csv", na = c("", "NA", "D", "K", "A", "NF"),locale = locale("fr")) 
base_externe3 <- base_externe3 %>% select( TIME,OUT,WT,DOSE,EVID,CLSC,ID,DOSE,INTERDOSE)%>% rename (Pds=WT, Clcreat =CLSC )%>% mutate(lieu="canada") %>% mutate(greffe="solide") #%>% filter (EVID=="1")

### il faut calculer taille a partir SC modififié 
summary(base_externe3)
base_externe3 <- base_externe3 %>% mutate(SC_mosteller= (4*Pds+7)/(90+Pds))  %>% mutate(taille= ((3600*SC_mosteller*SC_mosteller)/Pds)) %>% select(OUT,TIME,Pds,taille, Clcreat,ID,SC_mosteller,DOSE,INTERDOSE)
base_externe3$DOSE=as.numeric(base_externe3$DOSE)
### il faut rajouter age  
library(readxl)
age_base3 <- read_xls("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/PK-GCV_demog_val20190530_code.xls") 

age_base3 <- age_base3  %>% mutate(ID2=str_replace_all(age_base3$ID, "D", " "))%>% select(ID2,age,sex)%>% rename(ID=ID2)  %>% mutate(SEX=case_when(sex=="1"~"garcon",sex=="2"~"fille"))

age_base3 <- age_base3  %>% dplyr::add_row(ID = "90a", age=8.77,SEX="garcon") %>% dplyr::add_row(ID = "90b", age=8.77,SEX="garcon") %>% dplyr::add_row(ID = "90c", age=8.77,SEX="garcon") %>% dplyr::add_row(ID = "231a", age=0.63,SEX="garcon") %>% dplyr::add_row(ID = "231b", age=0.63,SEX="garcon")%>% dplyr::add_row(ID = "231c", age=0.63,SEX="garcon") %>% dplyr::add_row(ID = "258a", age=16.22,SEX="fille") %>% dplyr::add_row(ID = "258b", age=16.22,SEX="fille") %>% dplyr::add_row(ID = "258c", age=16.22,SEX="fille") %>% dplyr::add_row(ID = "348a", age=1.04,SEX="garcon") %>% dplyr::add_row(ID = "348b", age=1.04,SEX="garcon") %>% dplyr::add_row(ID = "558a", age=5.87,SEX="garcon")%>% dplyr::add_row(ID = "558b", age=5.87,SEX="garcon")
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               

#base_externe4 <- base_externe3 %>% left_join(age_base3) %>% select(-DOSE)

base_externe4 <- merge(base_externe3,age_base3,group_by=ID,x.all=T) 

base_externe5 <- base_externe4 %>% filter(TIME==0) 
base_externe5 <-base_externe5%>% select(ID,DOSE)
base_externe4 <- base_externe4 %>% select(-DOSE)

base_externe6 <- merge(base_externe4,base_externe5,group_by=ID,x.all=T) 
  
txt1 <- read_table("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/AUC_ref_anemone_pk_gcv_conc_val150219_po.txt")

txt2 <- read_table("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/AUC_ref_anemone_val111219_po.txt")

txt3 <- read_table("~/OneDrive/thèsescience/ganciclovir/ganciclovir/base_externe/AUC_ref_trapeze_AA_20191217.txt") %>% rename(AUC_benedicte_trapeze=AUC_trapeze)


AUC_base_externe <- txt1 %>% bind_rows(txt2) %>% bind_rows(txt3)%>% rename (ID=Nom)

base_externe2$ID=as.character(base_externe2$ID)

base_externe2$INTERDOSE=as.numeric(base_externe2$INTERDOSE)

base_externe_fusion <- base_externe2 %>% bind_rows(base_externe6)

base_externe_final <- merge(base_externe_fusion,AUC_base_externe,group_by=ID,x.all=T)

#base_externe_final <- base_externe_fusion %>% left_join(AUC_base_externe)%>%rename(amt=DOSE)#%>% filter(!is.na(age)) %>% select(-sex)
base_externe_final$INTERDOSE=as.factor(base_externe_final$INTERDOSE)
summary(base_externe_final)


### on va faire la base avec out 1_6

base_externe_final2<-base_externe_final%>% mutate(amt_24=case_when(INTERDOSE=="12" ~DOSE*2,INTERDOSE=="24" ~DOSE,INTERDOSE=="0" ~DOSE)) %>% mutate(auc=case_when(INTERDOSE=="12" ~AUC_benedicte_trapeze*2,INTERDOSE=="24" ~AUC_benedicte_trapeze,INTERDOSE=="0" ~AUC_benedicte_trapeze))%>% select(-DOSE)%>% rename(amt=amt_24)#%>% select(-auc)



base_externe_final3 <- base_externe_final2 %>% 
  mutate(time_bin = factor(case_when(between(TIME ,1.8, 2.2) ~"out_2",
         between(TIME ,5.2, 8.5) ~"out_6"))) %>% filter(!is.na(time_bin))#%>% dplyr::filter (!EVID=="1")

#base_externe_finalIV_term_2 <- base_externe_finalIV_term %>% 
  #mutate(time_bin = factor(case_when(TIME==0 ~ "out_0",
   #      TIME==3 ~"out_3"))) %>% filter(!is.na(time_bin))%>% dplyr::filter (!EVID=="1")

base_externe_final3 <- base_externe_final3 %>% arrange(ID)
summary(base_externe_final3)


base_externe_final3_long <- base_externe_final3 %>% ungroup %>% pivot_wider(id_cols=c(ID,Pds,Clcreat,age,taille,SEX,greffe,amt,auc),names_from =  time_bin ,values_from = OUT,values_fn=mean,names_repair="minimal")

base_externe_final3_long2 <- base_externe_final3_long  %>% filter(!is.na(out_2)) %>% filter(!is.na(out_6)) %>% mutate(SC_mosteller= (4*Pds+7)/(90+Pds)) %>% filter(!is.na(amt)) %>% select(-greffe)%>% mutate(greffe="solide") %>% mutate(dose_mg=amt/Pds)

summary(base_externe_final3_long2) 

base_externe_final3_long_out<- base_externe_final2%>% 
  mutate(time_bin = factor(case_when(TIME  < 0.1 ~ "out_0",
         between(TIME ,0.1,0.6)~"out_0.5",
         between(TIME ,0.7, 1.1) ~"out_1",
         between(TIME ,1.2, 1.7) ~"out_1.5",
         between(TIME ,1.8, 2.3) ~"out_2",
         between(TIME ,2.3, 2.7) ~"out_2.5",
         between(TIME ,2.8, 3.3) ~"out_3",
         between(TIME ,3.4, 3.7) ~"out_3.5",
         between(TIME ,3.8, 4.4) ~"out_4",
         between(TIME ,4.9, 5.4) ~"out_5",
         between(TIME ,5.9, 6.4) ~"out_6",
         between(TIME ,6.9, 7.4) ~"out_7",
         between(TIME ,7.9, 8.4) ~"out_8",
         between(TIME ,8.9, 9.4) ~"out_9",
         between(TIME ,9.9, 10.4) ~"out_10",
         between(TIME ,11.9, 12.4) ~"out_12", 
         between(TIME ,13.9, 14.4) ~"out_14", 
         between(TIME ,15.9, 16.4) ~"out_16", 
         between(TIME ,17.9, 18.4) ~"out_18",
         between(TIME ,19.8, 20.4) ~"out_20",
         between(TIME ,23.9, 24.4) ~"out_24")))




base_externe_final3_long_out_range <- base_externe_final3_long_out%>% filter(time_bin=="out_6")
summary(base_externe_final3_long_out)
base_externe_final3_long_bis_bis <- base_externe_final3_long_out %>% ungroup %>% pivot_wider(id_cols=c(ID,Pds,Clcreat,age,taille,SEX,greffe,amt,auc),names_from =  time_bin ,values_from = OUT,values_fn=mean,names_repair="minimal")

summary(base_externe_final3_long_bis_bis)

```
base externe predict

```{r}




predict_baseext_2_6=predict(final_wf_xgb_2_6,base_externe_final3_long2)%>%
     bind_cols(auc=base_externe_final3_long2$auc) %>%
  mutate (bias_rel = (.pred - auc)/auc,
          bias_rel_square = bias_rel * bias_rel)



rmarkdown::paged_table(as.data.frame(predict_baseext_2_6 %>% summarise(biais_rel = mean(bias_rel), relative_rmse = sqrt(mean(bias_rel_square)),biais_out_20percent = mean(!between(bias_rel,-0.2, 0.2)), nb_out_20percent = sum(!between(bias_rel,-0.2, 0.2)),biais_out_10percent = mean(!between(bias_rel,-0.1, 0.1)), nb_out_10percent = sum(!between(bias_rel,-0.1, 0.1)), n= n())))

predict_baseext_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) 

predict_baseext_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc-.pred)) + 
  geom_point() +
  geom_smooth(method=lm)


fm <-predict_baseext_2_6 %>%
  ggplot(mapping = aes(x = .pred, y = auc)) + 
  geom_point() +
  geom_smooth(method=lm) +labs(
    x = "Predicted AUC ",
    y = "Reference AUC ") + scale_y_continuous(breaks=c(20,30,40,50,60,70)) + theme_bw()


library(knitr)
library(blandr)

statistics.results <- blandr.statistics( predict_baseext_2_6$auc , predict_baseext_2_6$.pred )

fg <-blandr.plot.ggplot( statistics.results , plotTitle = "" , ciDisplay = F, ciShading = FALSE)+theme_bw()

library(gridExtra)

grid.arrange(fm,fg,ncol=2, nrow=1)

grid.arrange(pm,bg,ncol=2, nrow=1)
library(cowplot)
total_graph_VGCV <- plot_grid(pm,bg,fm,fg ,ncol=2, nrow=2, labels = "AUTO")
total_graph_VGCV

ggsave("total_graph_VGCV.tiff", units="in", width=5, height=5, dpi=300, compression = 'lzw')


auc_train_test_2_6

```



